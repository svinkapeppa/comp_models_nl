{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 09-Summarization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqkLTkFRfXvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! wget -q https://www.dropbox.com/s/43l702z5a5i2w8j/gazeta_train.txt\n",
        "! wget -q https://www.dropbox.com/s/k2egt3sug0hb185/gazeta_val.txt\n",
        "! wget -q https://www.dropbox.com/s/3gki5n5djs9w0v6/gazeta_test.txt\n",
        "! wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
        "! gunzip -k cc.en.300.bin.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXS1sdYZCluU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install --upgrade razdel allennlp torch fasttext OpenNMT-py networkx pymorphy2 nltk rouge==0.3.1 summa sentencepiece==0.1.8 transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPkq9fXSJX3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "import math\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "from itertools import combinations\n",
        "from collections import Counter, namedtuple\n",
        "from typing import List, Tuple\n",
        "\n",
        "import razdel\n",
        "import pymorphy2\n",
        "import fasttext\n",
        "\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
        "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
        "\n",
        "from rouge import Rouge\n",
        "from summa.summarizer import summarize\n",
        "from sentencepiece import SentencePieceTrainer\n",
        "from sentencepiece import SentencePieceProcessor\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liva5vCf3pVQ",
        "colab_type": "text"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eesnclfDDV3F",
        "colab_type": "text"
      },
      "source": [
        "## Data structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz6CZYKQhnd-",
        "colab_type": "code",
        "outputId": "a9209f45-89ef-4bc3-8426-acf0dd45841f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "! head -n 1 gazeta_train.txt\n",
        "! cat gazeta_train.txt | wc -l\n",
        "! cat gazeta_val.txt | wc -l\n",
        "! cat gazeta_test.txt | wc -l"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"url\": \"https://www.gazeta.ru/financial/2011/11/30/3852658.shtml\", \"text\": \"«По итогам 2011 года чистый отток может составить примерно $80 млрд, в следующем году — около $20 млрд. При этом мы ожидаем, что со второго полугодия 2012 года начнется приток капитала», — заявил «Интерфаксу» замминистра экономического развития Андрей Клепач. Официальные прогнозы по выводу капитала из России становятся все пессимистичными: еще летом власти полагали, что из страны уйдет не более $35 млрд, в сентябре Минэкономразвития назвал цифру $50 млрд, в начале ноября Центробанк пересмотрел оценку до $70 млрд. Очередное изменение прогноза было ожидаемо: по расчетам Центробанка , за январь — октябрь чистый отток капитала достиг $64 млрд, причем в последние месяцы он ускорился: в сентябре он составил $14 млрд, в октябре — $13 млрд против среднего ежемесячного оттока в $6—8 млрд в первом полугодии. «После октябрьских данных Минэкономразвития вынуждено было изменить оценку, настаивать на $70 млрд означало ожидать серьезного замедления оттока капитала на непонятно каких причинах», — говорит главный экономист BNP Paribas Юлия Цепляева. «В последние два месяца отток капитала ускорится, на декабрь приходится значительная часть выплат по внешним долгам, что приводит к усилению оттока, особенно если они не рефинансируются новыми кредитами», — соглашается главный экономист ФК «Открытие» Владимир Тихомиров. Прогнозируемый Минэкономразвития отток капитала — один из самых высоких за последние 20 лет. Больше ушло лишь в 2008 году на фоне разрастания финансового кризиса и российско-грузинской войны — $133,7 млрд. В кризисный 2009 год из России утекло $56,1 млрд. Главный фактор ускорения оттока капитала в 2011 году — нестабильность на внешних финансовых рынках и рост опасений относительно второй волны рецессии. «Это реакция на неуверенность, которую генерирует Европа с долговыми проблемами. В случае новой волны глобальной турбулентности Россия — одна из самых уязвимых стран», — говорит Цепляева. Еще одна причина — ослабление рубля. «Привлекательность вложений снижается на фоне того, что рубль перестал укрепляться, а ставки по депозитам достаточно низкие. В результате экспортеры не полностью возвращают экспортную выручку», — говорит Тихомиров. Внутри страны эксперты не видят особых причин для бегства капитала. «Ситуация выглядит достаточно позитивно, очень хорошие макроэкономические результаты за год, особенно на фоне других стран. С политической точки зрения все достаточно понятно и предсказуемо, итог выборов очевиден», — говорит экономист ИК «Тройка Диалог» Антон Струченевский. Тем не менее политический фактор играет роль. «Бизнесу важно не только, кто будет президентом, он ждет ясности с перестановками в правительстве. В наших условиях административный ресурс важнее всего для успешности бизнеса», — говорит Цепляева, добавляя, что отток капитала продолжится до завершения президентских выборов.\", \"title\": \"Прогноз не успевает за оттоком\", \"summary\": \"В 2011 году из России уйдет $80 млрд, считают в Минэкономразвития. Менее месяца назад Центробанк давал оценку $70 млрд, повысив первоначальный прогноз вдвое. Отток капитала из страны усиливается из-за кризиса в Европе, а в декабре российским компаниям выплачивать внешние долги. На движение капитала повлияли и выборы: несмотря на их предсказуемость, бизнес хочет ясности с перестановками в правительстве.\", \"date\": \"2011-11-30 18:33:39\"}\n",
            "52400\n",
            "5265\n",
            "5770\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pZ2UGS2DGjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_gazeta_records(file_name, shuffle=True, sort_by_date=False):\n",
        "    assert shuffle != sort_by_date\n",
        "\n",
        "    records = []\n",
        "    with open(file_name, \"r\") as r:\n",
        "        for line in r:\n",
        "            records.append(json.loads(line))\n",
        "\n",
        "    if sort_by_date:\n",
        "        records.sort(key=lambda x: x[\"date\"])\n",
        "    if shuffle:\n",
        "        random.shuffle\n",
        "\n",
        "    return records"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNDp-BunEA91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_records = read_gazeta_records(\"gazeta_train.txt\")\n",
        "val_records = read_gazeta_records(\"gazeta_val.txt\")\n",
        "test_records = read_gazeta_records(\"gazeta_test.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMNEBp7HRjE3",
        "colab_type": "code",
        "outputId": "f448c17e-f7a4-4806-89a6-5ecf6fdaf4f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(min([record[\"date\"] for record in train_records]))\n",
        "print(max([record[\"date\"] for record in train_records]))\n",
        "print(min([record[\"date\"] for record in val_records]))\n",
        "print(max([record[\"date\"] for record in val_records]))\n",
        "print(min([record[\"date\"] for record in test_records]))\n",
        "print(max([record[\"date\"] for record in test_records]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2010-06-01 10:35:49\n",
            "2019-05-31 23:56:26\n",
            "2019-06-01 08:30:00\n",
            "2019-09-30 23:11:23\n",
            "2019-10-01 08:23:02\n",
            "2020-03-23 22:16:23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izcJJT4dDZ_X",
        "colab_type": "text"
      },
      "source": [
        "## Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5qEd6ZqENzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Stats = namedtuple(\"Stats\", \"vocabulary,lemma_vocabulary,words_counts,unique_words_counts\")\n",
        "\n",
        "def collect_stats(records, lower=True, text_max_words=3000, summary_max_words=100, nrows=1000):\n",
        "    morph = pymorphy2.MorphAnalyzer()\n",
        "    \n",
        "    text_stats = Stats(Counter(),  Counter(), list(), list())\n",
        "    summary_stats = Stats(Counter(),  Counter(), list(), list())\n",
        "\n",
        "    def update_record_field_stats(field, stats, max_words):\n",
        "        words = [word.text for word in razdel.tokenize(field)][:max_words]\n",
        "\n",
        "        lemmas = [morph.parse(word)[0].normal_form for word in words]\n",
        "        stats.vocabulary.update(words)\n",
        "        stats.lemma_vocabulary.update(lemmas)\n",
        "        stats.words_counts.append(len(words))\n",
        "        stats.unique_words_counts.append(len(set(words)))\n",
        "\n",
        "    for i, record in enumerate(records):\n",
        "        if i >= nrows:\n",
        "            break\n",
        "\n",
        "        text = record[\"text\"]\n",
        "        text = text if not lower else text.lower()\n",
        "        update_record_field_stats(text, text_stats, text_max_words)\n",
        "\n",
        "        summary = record[\"summary\"]\n",
        "        summary = summary if not lower else summary.lower()\n",
        "        summary_words = [word.text for word in razdel.tokenize(summary)]\n",
        "        update_record_field_stats(summary, summary_stats, summary_max_words)\n",
        "\n",
        "    return text_stats, summary_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLUDxCr-e-w3",
        "colab_type": "code",
        "outputId": "3613267f-6a5c-4d89-cf0a-987af5667ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "test_text_stats, test_summary_stats = collect_stats(test_records)\n",
        "common_lemmas = set(test_text_stats.lemma_vocabulary.keys()) & set(test_summary_stats.lemma_vocabulary.keys())\n",
        "\n",
        "print(\"Test texts vocabulary size: \", len(test_text_stats.vocabulary))\n",
        "print(\"Test texts lemma vocabulary size: \", len(test_text_stats.lemma_vocabulary))\n",
        "print(\"Test summaries vocabulary size: \", len(test_summary_stats.vocabulary))\n",
        "print(\"Test summaries lemma vocabulary size: \", len(test_summary_stats.lemma_vocabulary))\n",
        "print(\"Test common lemmas summary vs text: \", len(common_lemmas))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test texts vocabulary size:  73282\n",
            "Test texts lemma vocabulary size:  32752\n",
            "Test summaries vocabulary size:  15196\n",
            "Test summaries lemma vocabulary size:  8673\n",
            "Test common lemmas summary vs text:  8408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RnVjYhVJpHY",
        "colab_type": "code",
        "outputId": "9c6f0f39-deba-4a2c-86b1-947fe498472e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "test_text_stats.lemma_vocabulary.most_common(25)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 54104),\n",
              " ('.', 38406),\n",
              " ('в', 28069),\n",
              " ('и', 14555),\n",
              " ('«', 12789),\n",
              " ('»', 12716),\n",
              " ('на', 11741),\n",
              " ('что', 9225),\n",
              " ('—', 8528),\n",
              " ('с', 8173),\n",
              " ('не', 7279),\n",
              " ('по', 6354),\n",
              " ('быть', 6232),\n",
              " ('он', 6206),\n",
              " ('это', 5730),\n",
              " ('год', 4998),\n",
              " ('который', 3920),\n",
              " ('о', 3888),\n",
              " ('тот', 3200),\n",
              " ('как', 2981),\n",
              " ('из', 2868),\n",
              " ('к', 2828),\n",
              " ('россия', 2713),\n",
              " ('она', 2659),\n",
              " ('они', 2632)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6BohYCZJH7H",
        "colab_type": "code",
        "outputId": "c6c06487-8d31-4e89-c61d-2fcecdd0d66b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.hist(test_text_stats.words_counts, 20)\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvE1j1P8NSvx",
        "colab_type": "code",
        "outputId": "f8f5a452-855d-4d0a-8242-ed583813a8a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.hist(test_text_stats.unique_words_counts, 20)\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYKvqKwfSCaC",
        "colab_type": "code",
        "outputId": "3c603503-d353-48d9-a06d-7e170f971cab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.hist(test_summary_stats.words_counts, 20)\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHNXD0xBNcY0",
        "colab_type": "code",
        "outputId": "810701b2-aecf-49cb-d294-0a24a5bd02b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "train_text_stats, train_summary_stats = collect_stats(train_records)\n",
        "common_lemmas = set(train_text_stats.lemma_vocabulary.keys()) & set(train_summary_stats.lemma_vocabulary.keys())\n",
        "\n",
        "print(\"Train texts vocabulary size: \", len(train_text_stats.vocabulary))\n",
        "print(\"Train texts lemma vocabulary size: \", len(train_text_stats.lemma_vocabulary))\n",
        "print(\"Train summaries vocabulary size: \", len(train_summary_stats.vocabulary))\n",
        "print(\"Train summaries lemma vocabulary size: \", len(train_summary_stats.lemma_vocabulary))\n",
        "print(\"Train common lemmas summary vs text: \", len(common_lemmas))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train texts vocabulary size:  82978\n",
            "Train texts lemma vocabulary size:  38089\n",
            "Train summaries vocabulary size:  15441\n",
            "Train summaries lemma vocabulary size:  9087\n",
            "Train common lemmas summary vs text:  8703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvj9vPaQNtz6",
        "colab_type": "code",
        "outputId": "ace114aa-add9-43fe-d8a4-1f6c1ea3d395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "common_lemmas = set(train_text_stats.lemma_vocabulary.keys()) & set(test_text_stats.lemma_vocabulary.keys())\n",
        "print(\"Text common lemmas train vs test: \", len(common_lemmas))\n",
        "\n",
        "common_lemmas = set(train_summary_stats.lemma_vocabulary.keys()) & set(test_summary_stats.lemma_vocabulary.keys())\n",
        "print(\"Summary common lemmas train vs test: \", len(common_lemmas))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text common lemmas train vs test:  18875\n",
            "Summary common lemmas train vs test:  4508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CJCd1qZOl6P",
        "colab_type": "code",
        "outputId": "63a85d7a-7064-4d4b-c2f5-77564a27a8f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.hist(train_text_stats.words_counts, 20)\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1sl7s2qB-N_",
        "colab_type": "text"
      },
      "source": [
        "# Lead-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fVfdfCyCALH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_scores(references, predictions, metric=\"all\"):\n",
        "    print(\"Count:\", len(predictions))\n",
        "    print(\"Ref:\", references[-1])\n",
        "    print(\"Hyp:\", predictions[-1])\n",
        "\n",
        "    if metric in (\"bleu\", \"all\"):\n",
        "        print(\"BLEU: \", corpus_bleu([[r] for r in references], predictions))\n",
        "    if metric in (\"rouge\", \"all\"):\n",
        "        rouge = Rouge()\n",
        "        scores = rouge.get_scores(predictions, references, avg=True)\n",
        "        print(\"ROUGE: \", scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAo9zv_rPtb6",
        "colab_type": "code",
        "outputId": "38614d81-e94d-44a3-924f-8b8d788ecab4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "def calc_lead_n_score(records, n=3, lower=True, nrows=1000):\n",
        "    references = []\n",
        "    predictions = []\n",
        "\n",
        "    for i, record in enumerate(records):\n",
        "        if i >= nrows:\n",
        "            break\n",
        "\n",
        "        summary = record[\"summary\"]\n",
        "        summary = summary if not lower else summary.lower()\n",
        "        references.append(summary)\n",
        "\n",
        "        text = record[\"text\"]\n",
        "        text = text if not lower else text.lower()\n",
        "        sentences = [sentence.text for sentence in razdel.sentenize(text)]\n",
        "        prediction = \" \".join(sentences[:n])\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    calc_scores(references, predictions)\n",
        "\n",
        "calc_lead_n_score(test_records, n=1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count: 1000\n",
            "Ref: телеканал «спас» запускает реалити-шоу «остров», участникам которого предстоит месяц жить и работать в нило-столобенской пустыни на озере селигер. организаторы отметили, что это беспрецедентный подобный проект на телевидении. участникам шоу будет, где поработать — в монастыре работают свечной, молочный и столярный цеха, есть коровник, конюшня, пасека.\n",
            "Hyp: православный телеканал «спас», учредителем которого является московская патриархия, запускает реалити-шоу «остров», участникам которого предстоит месяц жить и работать в нило-столобенской пустыни на озере селигер в тверской области.\n",
            "BLEU:  0.19177311186434495\n",
            "ROUGE:  {'rouge-1': {'f': 0.23804097238957525, 'p': 0.22208274285774904, 'r': 0.37762764047433917}, 'rouge-2': {'f': 0.10027796832321115, 'p': 0.09647636782929753, 'r': 0.15833772153385062}, 'rouge-l': {'f': 0.1835646488408507, 'p': 0.2022959168891477, 'r': 0.34937017731940756}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsAcVSli3r3S",
        "colab_type": "text"
      },
      "source": [
        "# TextRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2GwyRrMPAzS",
        "colab_type": "code",
        "outputId": "a7f3113a-46be-47e6-dec9-0e823fa9e346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "def unique_words_similarity(words1, words2):\n",
        "    \"\"\"\n",
        "    Function for calculating similarity of sentences based on the intersection of words\n",
        "    \"\"\"\n",
        "    words1 = set(words1)\n",
        "    words2 = set(words2)\n",
        "\n",
        "    if not len(words1) or not len(words2):\n",
        "        return 0.0\n",
        "\n",
        "    return len(words1.intersection(words2))/(np.log10(len(words1)) + np.log10(len(words2)))\n",
        "\n",
        "def gen_text_rank_summary(text, calc_similarity=unique_words_similarity, summary_part=0.1, lower=True, morph=None):\n",
        "    \"\"\"\n",
        "    Creating a summary using TextRank\n",
        "    \"\"\"\n",
        "    # Split text into sentences\n",
        "    sentences = [sentence.text for sentence in razdel.sentenize(text)]\n",
        "    n_sentences = len(sentences)\n",
        "\n",
        "    # Tokenization\n",
        "    sentences_words = [\n",
        "        [token.text.lower() if lower else token.text for token in razdel.tokenize(sentence)]\n",
        "        for sentence in sentences\n",
        "    ]\n",
        "\n",
        "    # Lemmatization\n",
        "    if morph is not None:\n",
        "        sentences_words = [[morph.parse(word)[0].normal_form for word in words] for words in sentences_words]\n",
        "\n",
        "    # Calculate sentence similarity for each pair of sentences\n",
        "    pairs = combinations(range(n_sentences), 2)\n",
        "    scores = [(i, j, calc_similarity(sentences_words[i], sentences_words[j])) for i, j in pairs]\n",
        "\n",
        "    # Create a graph with weights on edges equal to sentence similarities\n",
        "    g = nx.Graph()\n",
        "    g.add_weighted_edges_from(scores)\n",
        "\n",
        "    # Calculate PageRank\n",
        "    pr = nx.pagerank(g)\n",
        "    result = [(i, pr[i], s) for i, s in enumerate(sentences) if i in pr]\n",
        "    result.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Select top sentences\n",
        "    n_summary_sentences = max(int(n_sentences * summary_part), 1)\n",
        "    result = result[:n_summary_sentences]\n",
        "\n",
        "    # Recreate their original order\n",
        "    result.sort(key=lambda x: x[0])\n",
        "\n",
        "    # Recreate summary\n",
        "    predicted_summary = \" \".join([sentence for i, proba, sentence in result])\n",
        "    predicted_summary = predicted_summary.lower() if lower else predicted_summary\n",
        "\n",
        "    return predicted_summary\n",
        "\n",
        "def calc_text_rank_score(\n",
        "    records,\n",
        "    calc_similarity=unique_words_similarity,\n",
        "    summary_part=0.1,\n",
        "    lower=True,\n",
        "    nrows=1000,\n",
        "    morph=None,\n",
        "):\n",
        "    references = []\n",
        "    predictions = []\n",
        "\n",
        "    for i, record in enumerate(records):\n",
        "        if i >= nrows:\n",
        "            break\n",
        "\n",
        "        summary = record[\"summary\"]\n",
        "        summary = summary if not lower else summary.lower()\n",
        "        references.append(summary)\n",
        "\n",
        "        text = record[\"text\"]\n",
        "        predicted_summary = gen_text_rank_summary(text, calc_similarity, summary_part, lower, morph=morph)\n",
        "        text = text if not lower else text.lower()\n",
        "        predictions.append(predicted_summary)\n",
        "\n",
        "    calc_scores(references, predictions)\n",
        "\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "calc_text_rank_score(test_records)\n",
        "calc_text_rank_score(test_records, morph=morph)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count: 1000\n",
            "Ref: телеканал «спас» запускает реалити-шоу «остров», участникам которого предстоит месяц жить и работать в нило-столобенской пустыни на озере селигер. организаторы отметили, что это беспрецедентный подобный проект на телевидении. участникам шоу будет, где поработать — в монастыре работают свечной, молочный и столярный цеха, есть коровник, конюшня, пасека.\n",
            "Hyp: православный телеканал «спас», учредителем которого является московская патриархия, запускает реалити-шоу «остров», участникам которого предстоит месяц жить и работать в нило-столобенской пустыни на озере селигер в тверской области. проживи месяц в ниловой пустыни, выполняя послушания, и найди ответы на вопросы, которые давно беспокоят», — так анонсирует телеканал свой проект. в июне нынешнего года сообщалось, что рпц планирует сделать из сергиева посада «православный ватикан». по его словам, такая зависимость сродни алкогольной или наркотической — электронные устройства лишают человека свободы и приводят к «дегуманизации» личности, уводя в виртуальную реальность.\n",
            "BLEU:  0.27420412775325037\n",
            "ROUGE:  {'rouge-1': {'f': 0.16099517545563508, 'p': 0.13415311978229386, 'r': 0.21810822758753917}, 'rouge-2': {'f': 0.037251069184655726, 'p': 0.030061832039100414, 'r': 0.05353442921532314}, 'rouge-l': {'f': 0.12838445513376537, 'p': 0.1198821860587051, 'r': 0.1950002669162142}}\n",
            "Count: 1000\n",
            "Ref: телеканал «спас» запускает реалити-шоу «остров», участникам которого предстоит месяц жить и работать в нило-столобенской пустыни на озере селигер. организаторы отметили, что это беспрецедентный подобный проект на телевидении. участникам шоу будет, где поработать — в монастыре работают свечной, молочный и столярный цеха, есть коровник, конюшня, пасека.\n",
            "Hyp: православный телеканал «спас», учредителем которого является московская патриархия, запускает реалити-шоу «остров», участникам которого предстоит месяц жить и работать в нило-столобенской пустыни на озере селигер в тверской области. проживи месяц в ниловой пустыни, выполняя послушания, и найди ответы на вопросы, которые давно беспокоят», — так анонсирует телеканал свой проект. «если человеку невоцерковленному, далекому от церкви, в двух словах сказать, для чего нужна церковь — церковь… нужна для того, чтобы был силен дух нашего народа», — говорил предстоятель. по его словам, такая зависимость сродни алкогольной или наркотической — электронные устройства лишают человека свободы и приводят к «дегуманизации» личности, уводя в виртуальную реальность.\n",
            "BLEU:  0.27460926588128953\n",
            "ROUGE:  {'rouge-1': {'f': 0.1680169219415269, 'p': 0.13759449091881426, 'r': 0.23313126297426148}, 'rouge-2': {'f': 0.042434908605202624, 'p': 0.03399249591716803, 'r': 0.06180252883363982}, 'rouge-l': {'f': 0.13259093058909813, 'p': 0.1228074151426501, 'r': 0.20813288849342984}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac8UYVqJOLg6",
        "colab_type": "text"
      },
      "source": [
        "# Task 1\n",
        "\n",
        "Change sentence similarity function in TextRank algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFoXR5sxAD2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ft = fasttext.load_model(\"cc.en.300.bin\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll4hivHTZp6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fasttext_similarity(words1, words2):\n",
        "    emb1, emb2 = [], []\n",
        "\n",
        "    for word in words1:\n",
        "        emb1.append(ft.get_word_vector(word))\n",
        "    for word in words2:\n",
        "        emb2.append(ft.get_word_vector(word))\n",
        "\n",
        "    emb1 = np.mean(np.array(emb1), axis=0).reshape(1, -1)\n",
        "    emb2 = np.mean(np.array(emb2), axis=0).reshape(1, -1)\n",
        "\n",
        "    return cosine_similarity(emb1, emb2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgtzmKyxkJh2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "f10b35b0-06ec-45a1-94f5-5a39518f2c92"
      },
      "source": [
        "morph = pymorphy2.MorphAnalyzer()\n",
        "calc_text_rank_score(test_records, calc_similarity=fasttext_similarity)\n",
        "calc_text_rank_score(test_records, calc_similarity=fasttext_similarity, morph=morph)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count: 1000\n",
            "Ref: телеканал «спас» запускает реалити-шоу «остров», участникам которого предстоит месяц жить и работать в нило-столобенской пустыни на озере селигер. организаторы отметили, что это беспрецедентный подобный проект на телевидении. участникам шоу будет, где поработать — в монастыре работают свечной, молочный и столярный цеха, есть коровник, конюшня, пасека.\n",
            "Hyp: проживи месяц в ниловой пустыни, выполняя послушания, и найди ответы на вопросы, которые давно беспокоят», — так анонсирует телеканал свой проект. смирнов порассуждал, как можно допиться до «такой черной тоски, когда душа уже в аду», после чего заговорил о футболе. «если человеку невоцерковленному, далекому от церкви, в двух словах сказать, для чего нужна церковь — церковь… нужна для того, чтобы был силен дух нашего народа», — говорил предстоятель. по его словам, такая зависимость сродни алкогольной или наркотической — электронные устройства лишают человека свободы и приводят к «дегуманизации» личности, уводя в виртуальную реальность.\n",
            "BLEU:  0.2676161298814298\n",
            "ROUGE:  {'rouge-1': {'f': 0.14130983274522077, 'p': 0.11654174579267133, 'r': 0.19375764515849894}, 'rouge-2': {'f': 0.02575500141924123, 'p': 0.020902898193823693, 'r': 0.03668685201621713}, 'rouge-l': {'f': 0.11123191171205828, 'p': 0.10312906445879622, 'r': 0.17220919810969884}}\n",
            "Count: 1000\n",
            "Ref: телеканал «спас» запускает реалити-шоу «остров», участникам которого предстоит месяц жить и работать в нило-столобенской пустыни на озере селигер. организаторы отметили, что это беспрецедентный подобный проект на телевидении. участникам шоу будет, где поработать — в монастыре работают свечной, молочный и столярный цеха, есть коровник, конюшня, пасека.\n",
            "Hyp: проживи месяц в ниловой пустыни, выполняя послушания, и найди ответы на вопросы, которые давно беспокоят», — так анонсирует телеканал свой проект. смирнов порассуждал, как можно допиться до «такой черной тоски, когда душа уже в аду», после чего заговорил о футболе. «если человеку невоцерковленному, далекому от церкви, в двух словах сказать, для чего нужна церковь — церковь… нужна для того, чтобы был силен дух нашего народа», — говорил предстоятель. по его словам, такая зависимость сродни алкогольной или наркотической — электронные устройства лишают человека свободы и приводят к «дегуманизации» личности, уводя в виртуальную реальность.\n",
            "BLEU:  0.26951986623771756\n",
            "ROUGE:  {'rouge-1': {'f': 0.14323694444611146, 'p': 0.11873561071345715, 'r': 0.19542725157546703}, 'rouge-2': {'f': 0.027222883768564445, 'p': 0.022133272378943712, 'r': 0.038763079544357266}, 'rouge-l': {'f': 0.11294195629943596, 'p': 0.10519157893641515, 'r': 0.17369676958870583}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGFTmGLLFOGw",
        "colab_type": "text"
      },
      "source": [
        "# Summa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQiUDH8fVN3h",
        "colab_type": "code",
        "outputId": "2647ecf1-8c90-43ed-dd5d-944c860eb65b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "def calc_summa_score(records, summary_part=0.1, lower=True, nrows=1000):\n",
        "    references = []\n",
        "    predictions = []\n",
        "\n",
        "    for i, record in enumerate(records):\n",
        "        if i >= nrows:\n",
        "            break\n",
        "\n",
        "        summary = record[\"summary\"]\n",
        "        summary = summary if not lower else summary.lower()\n",
        "        references.append(summary)\n",
        "\n",
        "        text = record[\"text\"]\n",
        "        text = text if not lower else text.lower()\n",
        "        predicted_summary = summarize(text, ratio=summary_part, language='russian').replace(\"\\n\", \" \")\n",
        "        predictions.append(predicted_summary)\n",
        "\n",
        "    calc_scores(references, predictions)\n",
        "\n",
        "calc_summa_score(test_records)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count: 1000\n",
            "Ref: телеканал «спас» запускает реалити-шоу «остров», участникам которого предстоит месяц жить и работать в нило-столобенской пустыни на озере селигер. организаторы отметили, что это беспрецедентный подобный проект на телевидении. участникам шоу будет, где поработать — в монастыре работают свечной, молочный и столярный цеха, есть коровник, конюшня, пасека.\n",
            "Hyp: проживи месяц в ниловой пустыни, выполняя послушания, и найди ответы на вопросы, которые давно беспокоят», — так анонсирует телеканал свой проект. «у нас же даже многие журналисты не знают и не понимают многого, связанного с религиозными ценностями, а здесь — попытка обратить их внимание на это, может быть, им будет интересно. стоит отметить, что участникам шоу будет, где поработать — в монастыре работают свечной, молочный и столярный цеха, есть коровник, конюшня, пасека. и это что — жизнь, что ли?\n",
            "BLEU:  0.2762958192799957\n",
            "ROUGE:  {'rouge-1': {'f': 0.1770425497877709, 'p': 0.14391909693539454, 'r': 0.24737876331285494}, 'rouge-2': {'f': 0.047316399226292105, 'p': 0.03775600414501152, 'r': 0.06889084948510987}, 'rouge-l': {'f': 0.13869575224542852, 'p': 0.12795603134013936, 'r': 0.2198206686289155}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdTrfxycB7cd",
        "colab_type": "text"
      },
      "source": [
        "# Oracle summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q7DeHDYFSjX",
        "colab_type": "text"
      },
      "source": [
        "To solve this problem as an extractive summarization problem, we first need to select those sentences from the original text, that are most similar to the summary based on out metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxsc0Orf8hGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_oracle_summary_greedy(text, gold_summary, calc_score, lower=True, max_sentences=30):\n",
        "    \"\"\"\n",
        "    Gready oracle summary\n",
        "    \"\"\"\n",
        "    gold_summary = gold_summary.lower() if lower else gold_summary\n",
        "\n",
        "    # Split text into sentences\n",
        "    sentences = [\n",
        "        sentence.text.lower() if lower else sentence.text for sentence in razdel.sentenize(text)\n",
        "    ][:max_sentences]\n",
        "    n_sentences = len(sentences)\n",
        "\n",
        "    oracle_summary_sentences = set()\n",
        "    score = -1.0\n",
        "    summaries = []\n",
        "    for _ in range(n_sentences):\n",
        "        for i in range(n_sentences):\n",
        "            if i in oracle_summary_sentences:\n",
        "                continue\n",
        "            current_summary_sentences = copy.copy(oracle_summary_sentences)\n",
        "\n",
        "            # Add new sentence to already constructured summary\n",
        "            current_summary_sentences.add(i)\n",
        "            current_summary = \" \".join([sentences[index] for index in sorted(list(current_summary_sentences))])\n",
        "\n",
        "            # Calculate metrics\n",
        "            current_score = calc_score(current_summary, gold_summary)\n",
        "            summaries.append((current_score, current_summary_sentences))\n",
        "\n",
        "        # If metrics were improved, try to add new sentences\n",
        "        # Otherwise, terminate\n",
        "        best_summary_score, best_summary_sentences = max(summaries)\n",
        "        if best_summary_score <= score:\n",
        "            break\n",
        "\n",
        "        oracle_summary_sentences = best_summary_sentences\n",
        "        score = best_summary_score\n",
        "\n",
        "    oracle_summary = \" \".join([sentences[index] for index in sorted(list(oracle_summary_sentences))])\n",
        "\n",
        "    return oracle_summary, oracle_summary_sentences\n",
        "\n",
        "\n",
        "def calc_single_score(pred_summary, gold_summary, rouge):\n",
        "    return rouge.get_scores([pred_summary], [gold_summary], avg=True)[\"rouge-2\"][\"f\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T_ak-KDB8rp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7e535cff-cb8a-42bc-e934-c071896dc056"
      },
      "source": [
        "def calc_oracle_score(records, nrows=1000, lower=True):\n",
        "    references = []\n",
        "    predictions = []\n",
        "    rouge = Rouge()\n",
        "\n",
        "    for i, record in enumerate(records):\n",
        "        if i >= nrows:\n",
        "            break\n",
        "\n",
        "        summary = record[\"summary\"]\n",
        "        summary = summary if not lower else summary.lower()\n",
        "        references.append(summary)\n",
        "\n",
        "        text = record[\"text\"]\n",
        "        predicted_summary, _ = build_oracle_summary_greedy(\n",
        "            text, summary, calc_score=lambda x, y: calc_single_score(x, y, rouge)\n",
        "        )\n",
        "        predictions.append(predicted_summary)\n",
        "\n",
        "    calc_scores(references, predictions)\n",
        "\n",
        "calc_oracle_score(test_records)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count: 1000\n",
            "Ref: телеканал «спас» запускает реалити-шоу «остров», участникам которого предстоит месяц жить и работать в нило-столобенской пустыни на озере селигер. организаторы отметили, что это беспрецедентный подобный проект на телевидении. участникам шоу будет, где поработать — в монастыре работают свечной, молочный и столярный цеха, есть коровник, конюшня, пасека.\n",
            "Hyp: православный телеканал «спас», учредителем которого является московская патриархия, запускает реалити-шоу «остров», участникам которого предстоит месяц жить и работать в нило-столобенской пустыни на озере селигер в тверской области. в комментарии также отмечается, что это беспрецедентный подобный проект на телевидении. стоит отметить, что участникам шоу будет, где поработать — в монастыре работают свечной, молочный и столярный цеха, есть коровник, конюшня, пасека.\n",
            "BLEU:  0.531336150784986\n",
            "ROUGE:  {'rouge-1': {'f': 0.36951810858804146, 'p': 0.4053281117404892, 'r': 0.3661389123393327}, 'rouge-2': {'f': 0.2087846693590912, 'p': 0.23400300931194973, 'r': 0.20594499639015063}, 'rouge-l': {'f': 0.32342889691715343, 'p': 0.3777106006444112, 'r': 0.33982247044123787}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foLYftYTCAkS",
        "colab_type": "text"
      },
      "source": [
        "# Extractive RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Sfauc4VGgyw",
        "colab_type": "text"
      },
      "source": [
        "## BPE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qIRKm4TCHzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_bpe(records, model_path, model_type=\"bpe\", vocab_size=15000, lower=True):\n",
        "    temp_file_name = \"temp.txt\"\n",
        "\n",
        "    with open(temp_file_name, \"w\") as temp:\n",
        "        for record in train_records:\n",
        "            summary = record[\"summary\"].strip()\n",
        "            text = record[\"text\"].strip()\n",
        "\n",
        "            if lower:\n",
        "                summary = summary.lower()\n",
        "                text = text.lower()\n",
        "            if not text or not summary:\n",
        "                continue\n",
        "\n",
        "            temp.write(text + \"\\n\")\n",
        "            temp.write(summary + \"\\n\")\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        os.makedirs(model_path)\n",
        "\n",
        "    cmd = \"--input={} --model_prefix={} --vocab_size={} --model_type={}\".format(\n",
        "        temp_file_name,\n",
        "        os.path.join(model_path, model_type),\n",
        "        vocab_size,\n",
        "        model_type)\n",
        "\n",
        "    SentencePieceTrainer.Train(cmd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS4MmoqEltER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! rm -f bpe.model\n",
        "! rm -f bpe.vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79OxLTSNlvHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_bpe(train_records, \"./\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSMC-8J3g9MR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "04c3032c-423d-4c1f-fe6c-3657d6e089ae"
      },
      "source": [
        "! head bpe.vocab\n",
        "! cat bpe.vocab | wc -l"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<unk>\t0\n",
            "<s>\t0\n",
            "</s>\t0\n",
            "▁п\t-0\n",
            "▁с\t-1\n",
            "▁в\t-2\n",
            "ро\t-3\n",
            "ст\t-4\n",
            "ра\t-5\n",
            "на\t-6\n",
            "15000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAkZ2f5LhWwE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca458d70-0bf2-46e5-8058-f88cc46cf217"
      },
      "source": [
        "bpe_processor = SentencePieceProcessor()\n",
        "bpe_processor.Load(\"bpe.model\")\n",
        "\n",
        "def bpe_tokenize(text, bpe_processor):\n",
        "    return bpe_processor.EncodeAsPieces(text)\n",
        "\n",
        "bpe_tokenize(\"октябрь богат на изменения\", bpe_processor)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁октябрь', '▁бога', 'т', '▁на', '▁изменения']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOkUL_YIGp-S",
        "colab_type": "text"
      },
      "source": [
        "## Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhQYN1beiVEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self):\n",
        "        self.index2word = list()\n",
        "        self.word2index = dict()\n",
        "        self.word2count = Counter()\n",
        "        self.reset()\n",
        "\n",
        "    def get_pad(self):\n",
        "        return self.word2index[\"<pad>\"]\n",
        "\n",
        "    def get_sos(self):\n",
        "        return self.word2index[\"<sos>\"]\n",
        "\n",
        "    def get_eos(self):\n",
        "        return self.word2index[\"<eos>\"]\n",
        "\n",
        "    def get_unk(self):\n",
        "        return self.word2index[\"<unk>\"]\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = len(self.index2word)\n",
        "            self.word2count[word] += 1\n",
        "            self.index2word.append(word)\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "    \n",
        "    def has_word(self, word) -> bool:\n",
        "        return word in self.word2index\n",
        "\n",
        "    def get_index(self, word):\n",
        "        if word in self.word2index:\n",
        "            return self.word2index[word]\n",
        "        return self.get_unk()\n",
        "\n",
        "    def get_word(self, index):\n",
        "        return self.index2word[index]\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.index2word)\n",
        "\n",
        "    def is_empty(self):\n",
        "        empty_size = 4\n",
        "        return self.size() <= empty_size\n",
        "\n",
        "    def shrink(self, n):\n",
        "        best_words = self.word2count.most_common(n)\n",
        "        self.reset()\n",
        "        for word, count in best_words:\n",
        "            self.add_word(word)\n",
        "            self.word2count[word] = count\n",
        "\n",
        "    def reset(self):\n",
        "        self.word2count = Counter()\n",
        "        self.index2word = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]\n",
        "        self.word2index = {word: index for index, word in enumerate(self.index2word)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qvZtNcOifAn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5ba0313e-2bc8-4f99-e90c-14b6d9fcb430"
      },
      "source": [
        "def build_vocabulary(records, bpe_processor, lower=True): \n",
        "    vocabulary = Vocabulary()\n",
        "\n",
        "    for record in records:\n",
        "        text = record[\"text\"]\n",
        "        text = text.lower() if lower else text\n",
        "        tokens = bpe_tokenize(text, bpe_processor)\n",
        "\n",
        "        for token in tokens:\n",
        "            vocabulary.add_word(token)\n",
        "\n",
        "    return vocabulary\n",
        "\n",
        "vocabulary = build_vocabulary(train_records, bpe_processor)\n",
        "print(vocabulary.word2count.most_common(25)) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(',', 2467870), ('.', 1770601), ('▁в', 1432966), ('▁и', 856627), ('▁«', 769136), ('▁на', 667157), ('▁не', 458901), ('▁—', 423218), ('▁с', 407759), ('▁что', 399348), ('▁по', 355321), ('»', 349402), ('-', 299470), ('»,', 239006), ('▁за', 198471), ('▁а', 198254), ('▁из', 182499), ('».', 172453), ('▁о', 164747), ('▁к', 163134), ('▁у', 146741), ('▁от', 143396), ('▁но', 141837), ('▁как', 135981), ('ли', 128134)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seH13yXuGt03",
        "colab_type": "text"
      },
      "source": [
        "## Cache"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdb-39jO-72q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def add_oracle_summary_to_records(records, max_sentences=30, lower=True, nrows=1000):\n",
        "#     rouge = Rouge()\n",
        "\n",
        "#     for i, record in enumerate(records):\n",
        "#         if i >= nrows:\n",
        "#             break\n",
        "\n",
        "#         if i % 128 == 0:\n",
        "#             print(i)\n",
        "\n",
        "#         text = record[\"text\"]\n",
        "#         summary = record[\"summary\"]\n",
        "#         summary = summary.lower() if lower else summary\n",
        "#         sentences = [sentence.text.lower() if lower else sentence.text for sentence in razdel.sentenize(text)][:max_sentences]\n",
        "#         oracle_summary, sentences_indicies = build_oracle_summary_greedy(\n",
        "#             text, summary, calc_score=lambda x, y: calc_single_score(x, y, rouge), lower=lower, max_sentences=max_sentences\n",
        "#         )\n",
        "#         record[\"sentences\"] = sentences\n",
        "#         record[\"oracle_sentences\"] = list(sentences_indicies)\n",
        "#         record[\"oracle_summary\"] = oracle_summary\n",
        "\n",
        "#     return records[:nrows]\n",
        "\n",
        "# ext_train_records = add_oracle_summary_to_records(train_records, nrows=16384)\n",
        "# ext_val_records = add_oracle_summary_to_records(val_records, nrows=1024)\n",
        "# ext_test_records = add_oracle_summary_to_records(test_records, nrows=1024)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30tUpRQtq1fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def write_gazeta_records(records, file_name):\n",
        "#     with open(file_name, \"w\") as w:\n",
        "#         for record in records:\n",
        "#             record[\"oracle_sentences\"] = list(record[\"oracle_sentences\"])\n",
        "#             w.write(json.dumps(record, ensure_ascii=False).strip() + \"\\n\")\n",
        "\n",
        "# write_gazeta_records(ext_train_records, \"gazeta_train_with_oracle.txt\")\n",
        "# write_gazeta_records(ext_val_records, \"gazeta_val_with_oracle.txt\")\n",
        "# write_gazeta_records(ext_test_records, \"gazeta_test_with_oracle.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YRWEfu6royg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp \"gazeta_train_with_oracle.txt\" \"drive/My Drive/gazeta_train_with_oracle.txt\"\n",
        "# !cp \"gazeta_val_with_oracle.txt\" \"drive/My Drive/gazeta_val_with_oracle.txt\"\n",
        "# !cp \"gazeta_test_with_oracle.txt\" \"drive/My Drive/gazeta_test_with_oracle.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLSaFW5DI9xH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp \"drive/My Drive/gazeta_train_with_oracle.txt\" \"gazeta_train_with_oracle.txt\"\n",
        "# !cp \"drive/My Drive/gazeta_val_with_oracle.txt\" \"gazeta_val_with_oracle.txt\"\n",
        "# !cp \"drive/My Drive/gazeta_test_with_oracle.txt\" \"gazeta_test_with_oracle.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzyD29AQJHHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ext_train_records = read_gazeta_records(\"gazeta_train_with_oracle.txt\")\n",
        "ext_val_records = read_gazeta_records(\"gazeta_val_with_oracle.txt\")\n",
        "ext_test_records = read_gazeta_records(\"gazeta_test_with_oracle.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlXXc8qUHC5m",
        "colab_type": "text"
      },
      "source": [
        "## Batch Iterator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNyxstTChK3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BatchIterator():\n",
        "    def __init__(\n",
        "        self,\n",
        "        records,\n",
        "        vocabulary,\n",
        "        batch_size,\n",
        "        bpe_processor,\n",
        "        shuffle=True,\n",
        "        lower=True,\n",
        "        max_sentences=30,\n",
        "        max_sentence_length=50,\n",
        "        device=torch.device(\"cpu\")\n",
        "    ):\n",
        "        self.records = records\n",
        "        self.num_samples = len(records)\n",
        "        self.batch_size = batch_size\n",
        "        self.bpe_processor = bpe_processor\n",
        "        self.shuffle = shuffle\n",
        "        self.batches_count = int(math.ceil(self.num_samples / batch_size))\n",
        "        self.lower = lower\n",
        "        self.rouge = Rouge()\n",
        "        self.vocabulary = vocabulary\n",
        "        self.max_sentences = max_sentences\n",
        "        self.max_sentence_length = max_sentence_length\n",
        "        self.device = device\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.batches_count\n",
        "\n",
        "    def __iter__(self):\n",
        "        indices = np.arange(self.num_samples)\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "        for start in range(0, self.num_samples, self.batch_size):\n",
        "            end = min(start + self.batch_size, self.num_samples)\n",
        "            batch_indices = indices[start:end]\n",
        "            batch_inputs = []\n",
        "            batch_outputs = []\n",
        "            max_sentence_length = 0\n",
        "            max_sentences = 0\n",
        "            batch_records = []\n",
        "\n",
        "            for data_ind in batch_indices:\n",
        "                record = self.records[data_ind]\n",
        "                batch_records.append(record)\n",
        "                text = record[\"text\"]\n",
        "                summary = record[\"summary\"]\n",
        "                summary = summary.lower() if self.lower else summary\n",
        "\n",
        "                if \"sentences\" not in record:\n",
        "                    sentences = [\n",
        "                        sentence.text.lower() if self.lower else sentence.text for sentence in razdel.sentenize(text)\n",
        "                    ][:self.max_sentences]\n",
        "                else:\n",
        "                    sentences = record[\"sentences\"]\n",
        "                max_sentences = max(len(sentences), max_sentences)\n",
        "\n",
        "                if \"oracle_sentences\" not in record:\n",
        "                    calc_score = lambda x, y: calc_single_score(x, y, self.rouge)\n",
        "                    sentences_indicies = build_oracle_summary_greedy(\n",
        "                        text, summary, calc_score=calc_score, lower=self.lower, max_sentences=self.max_sentences\n",
        "                    )[1]\n",
        "                else:\n",
        "                    sentences_indicies = record[\"oracle_sentences\"]\n",
        "\n",
        "                inputs = [\n",
        "                    list(map(\n",
        "                        self.vocabulary.get_index,\n",
        "                        bpe_tokenize(sentence, self.bpe_processor)[:self.max_sentence_length]\n",
        "                    ))\n",
        "                    for sentence in sentences\n",
        "                ]\n",
        "                max_sentence_length = max(max_sentence_length, max([len(tokens) for tokens in inputs]))\n",
        "                outputs = [int(i in sentences_indicies) for i in range(len(sentences))]\n",
        "                batch_inputs.append(inputs)\n",
        "                batch_outputs.append(outputs)\n",
        "            tensor_inputs = torch.zeros(\n",
        "                (self.batch_size, max_sentences, max_sentence_length), dtype=torch.long, device=self.device\n",
        "            )\n",
        "            tensor_outputs = torch.zeros(\n",
        "                (self.batch_size, max_sentences), dtype=torch.float32, device=self.device\n",
        "            )\n",
        "            for i, inputs in enumerate(batch_inputs):\n",
        "                for j, sentence_tokens in enumerate(inputs):\n",
        "                    tensor_inputs[i][j][:len(sentence_tokens)] = torch.LongTensor(sentence_tokens)\n",
        "            for i, outputs in enumerate(batch_outputs):\n",
        "                tensor_outputs[i][:len(outputs)] = torch.LongTensor(outputs)\n",
        "\n",
        "            yield {\n",
        "                \"inputs\": tensor_inputs,\n",
        "                \"outputs\": tensor_outputs,\n",
        "                \"records\": batch_records\n",
        "            }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q2Gb6ODHHB_",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5ZApHkw2Jq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(\n",
        "    model,\n",
        "    train_records,\n",
        "    val_records,\n",
        "    vocabulary,\n",
        "    bpe_processor,\n",
        "    batch_size=32,\n",
        "    epochs_count=10,\n",
        "    loss_every_nsteps=16,\n",
        "    lr=0.001,\n",
        "    device_name=\"cuda\",\n",
        "):\n",
        "    params_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(\"Trainable params: {}\".format(params_count))\n",
        "\n",
        "    device = torch.device(device_name)\n",
        "    model = model.to(device)\n",
        "    total_loss = 0\n",
        "    start_time = time.time()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_function = nn.BCEWithLogitsLoss().to(device)\n",
        "\n",
        "    for epoch in range(epochs_count):\n",
        "        train_iter = BatchIterator(train_records, vocabulary, batch_size, bpe_processor, device=device)\n",
        "        val_iter = BatchIterator(val_records, vocabulary, batch_size, bpe_processor, device=device)\n",
        "\n",
        "        for step, batch in enumerate(train_iter):\n",
        "            model.train()\n",
        "\n",
        "            logits = model(batch[\"inputs\"])\n",
        "\n",
        "            loss = loss_function(logits, batch[\"outputs\"])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if step % loss_every_nsteps == 0 and step != 0:\n",
        "                val_total_loss = 0\n",
        "                val_batch_count = 0\n",
        "\n",
        "                model.eval()\n",
        "\n",
        "                for _, val_batch in enumerate(val_iter):\n",
        "                    logits = model(val_batch[\"inputs\"])\n",
        "                    val_total_loss += loss_function(logits, batch[\"outputs\"])\n",
        "                    val_batch_count += 1\n",
        "\n",
        "                avg_val_loss = val_total_loss/val_batch_count\n",
        "                print(\n",
        "                    \"Epoch = {}, Avg Train Loss = {:.4f}, Avg val loss = {:.4f}, Time = {:.2f}s\" \\\n",
        "                    .format(epoch, total_loss / loss_every_nsteps, avg_val_loss, time.time() - start_time)\n",
        "                )\n",
        "\n",
        "                total_loss = 0\n",
        "                start_time = time.time()\n",
        "\n",
        "        print(\"\\n\")\n",
        "\n",
        "        total_loss = 0\n",
        "        start_time = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYmCkxqbxoW1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "0f2de536-e1c4-4503-fec7-a2451a275c0f"
      },
      "source": [
        "class SentenceEncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_dim, hidden_size, n_layers=3, dropout=0.3, bidirectional=True):\n",
        "        super().__init__()\n",
        "\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        assert hidden_size % num_directions == 0\n",
        "        hidden_size = hidden_size // num_directions\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.embedding_layer = nn.Embedding(input_size, embedding_dim)\n",
        "        self.rnn_layer = nn.LSTM(\n",
        "            embedding_dim,\n",
        "            hidden_size,\n",
        "            n_layers,\n",
        "            dropout=dropout,\n",
        "            bidirectional=bidirectional,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.dropout_layer = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, inputs, hidden=None):\n",
        "        embedded = self.embedding_layer(inputs)\n",
        "        outputs, _ = self.rnn_layer(embedded, hidden)\n",
        "        sentences_embeddings = torch.mean(outputs, 1)\n",
        "\n",
        "        return sentences_embeddings\n",
        "\n",
        "class SentenceTaggerRNN(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocabulary_size,\n",
        "        token_embedding_dim=256,\n",
        "        sentence_encoder_hidden_size=256,\n",
        "        hidden_size=256,\n",
        "        bidirectional=True,\n",
        "        sentence_encoder_n_layers=2,\n",
        "        sentence_encoder_dropout=0.3,\n",
        "        sentence_encoder_bidirectional=True,\n",
        "        n_layers=1,\n",
        "        dropout=0.3,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        assert hidden_size % num_directions == 0\n",
        "        hidden_size = hidden_size // num_directions\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.sentence_encoder = SentenceEncoderRNN(\n",
        "            vocabulary_size,\n",
        "            token_embedding_dim,\n",
        "            sentence_encoder_hidden_size,\n",
        "            sentence_encoder_n_layers,\n",
        "            sentence_encoder_dropout,\n",
        "            sentence_encoder_bidirectional\n",
        "        )\n",
        "        self.rnn_layer = nn.LSTM(\n",
        "            sentence_encoder_hidden_size,\n",
        "            hidden_size,\n",
        "            n_layers,\n",
        "            dropout=dropout,\n",
        "            bidirectional=bidirectional,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.dropout_layer = nn.Dropout(dropout)\n",
        "        self.content_linear_layer = nn.Linear(hidden_size * 2, 1)\n",
        "        self.document_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
        "        self.salience_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
        "        self.tanh_layer = nn.Tanh()\n",
        "\n",
        "    def forward(self, inputs, hidden=None):\n",
        "        batch_size = inputs.size(0)\n",
        "        sentences_count = inputs.size(1)\n",
        "        tokens_count = inputs.size(2)\n",
        "        inputs = inputs.reshape(-1, tokens_count)\n",
        "        embedded_sentences = self.sentence_encoder(inputs)\n",
        "        embedded_sentences = embedded_sentences.reshape(batch_size, sentences_count, -1)\n",
        "        outputs, _ = self.rnn_layer(embedded_sentences, hidden)\n",
        "        outputs = self.dropout_layer(outputs)\n",
        "        document_embedding = self.tanh_layer(self.document_linear_layer(torch.mean(outputs, 1)))\n",
        "        content = self.content_linear_layer(outputs).squeeze(2)\n",
        "        salience = torch.bmm(outputs, self.salience_linear_layer(document_embedding).unsqueeze(2)).squeeze(2)\n",
        "\n",
        "        return content + salience\n",
        "\n",
        "model = SentenceTaggerRNN(vocabulary.size())\n",
        "train_model(\n",
        "    model,\n",
        "    ext_train_records,\n",
        "    ext_val_records,\n",
        "    vocabulary,\n",
        "    bpe_processor,\n",
        "    device_name=\"cuda\",\n",
        "    batch_size=32,\n",
        "    epochs_count=4,\n",
        "    loss_every_nsteps=100\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Trainable params: 5250305\n",
            "Epoch = 0, Avg Train Loss = 0.2571, Avg val loss = 0.2533, Time = 26.08s\n",
            "Epoch = 0, Avg Train Loss = 0.2318, Avg val loss = 0.2639, Time = 25.59s\n",
            "Epoch = 0, Avg Train Loss = 0.2288, Avg val loss = 0.2238, Time = 25.87s\n",
            "Epoch = 0, Avg Train Loss = 0.2272, Avg val loss = 0.2499, Time = 25.72s\n",
            "Epoch = 0, Avg Train Loss = 0.2234, Avg val loss = 0.2520, Time = 25.65s\n",
            "\n",
            "\n",
            "Epoch = 1, Avg Train Loss = 0.2224, Avg val loss = 0.2564, Time = 25.77s\n",
            "Epoch = 1, Avg Train Loss = 0.2158, Avg val loss = 0.2557, Time = 25.68s\n",
            "Epoch = 1, Avg Train Loss = 0.2204, Avg val loss = 0.2192, Time = 25.67s\n",
            "Epoch = 1, Avg Train Loss = 0.2181, Avg val loss = 0.2734, Time = 25.51s\n",
            "Epoch = 1, Avg Train Loss = 0.2183, Avg val loss = 0.2623, Time = 25.84s\n",
            "\n",
            "\n",
            "Epoch = 2, Avg Train Loss = 0.2078, Avg val loss = 0.2379, Time = 25.74s\n",
            "Epoch = 2, Avg Train Loss = 0.2063, Avg val loss = 0.2720, Time = 25.71s\n",
            "Epoch = 2, Avg Train Loss = 0.2082, Avg val loss = 0.2870, Time = 25.69s\n",
            "Epoch = 2, Avg Train Loss = 0.2080, Avg val loss = 0.2407, Time = 25.70s\n",
            "Epoch = 2, Avg Train Loss = 0.2082, Avg val loss = 0.2391, Time = 25.72s\n",
            "\n",
            "\n",
            "Epoch = 3, Avg Train Loss = 0.1854, Avg val loss = 0.3002, Time = 25.94s\n",
            "Epoch = 3, Avg Train Loss = 0.1850, Avg val loss = 0.2889, Time = 25.86s\n",
            "Epoch = 3, Avg Train Loss = 0.1853, Avg val loss = 0.2870, Time = 25.61s\n",
            "Epoch = 3, Avg Train Loss = 0.1926, Avg val loss = 0.3006, Time = 25.75s\n",
            "Epoch = 3, Avg Train Loss = 0.1874, Avg val loss = 0.2778, Time = 25.68s\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwqhK2dyKuGL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "2323f7b2-fec3-4efd-fe47-4830ec48692e"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "references = []\n",
        "predictions = []\n",
        "for step, batch in enumerate(BatchIterator(ext_test_records, vocabulary, 32, bpe_processor, device=device)):\n",
        "    logits = model(batch[\"inputs\"])\n",
        "    records = batch[\"records\"]\n",
        "\n",
        "    for record, record_logits in zip(records, logits):\n",
        "        sentences = record[\"sentences\"]\n",
        "\n",
        "        predicted_summary = []\n",
        "        for i, logit in enumerate(record_logits):\n",
        "            if logit > 0.0:\n",
        "                predicted_summary.append(sentences[i])\n",
        "\n",
        "        if not predicted_summary:\n",
        "            predicted_summary.append(sentences[torch.max(record_logits, dim=0)[1].item()])\n",
        "\n",
        "        predicted_summary = \" \".join(predicted_summary)\n",
        "        references.append(record[\"summary\"].lower())\n",
        "        predictions.append(predicted_summary)\n",
        "\n",
        "calc_scores(references, predictions)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count: 1024\n",
            "Ref: поп-исполнительница лана дель рей из-за болезни была вынуждена отменить тур по европе и великобритании. по несчастному совпадению, в это же время от своих ближайших выступлений были вынуждены отказаться британцы элтон джон и оззи озборн.\n",
            "Hyp: американская певица лана дель рей отменила свой тур по европе и великобритании из-за болезни, которая привела к потери голоса, пишет variety.\n",
            "BLEU:  0.2095700325102749\n",
            "ROUGE:  {'rouge-1': {'f': 0.21692709565554935, 'p': 0.3375305655874032, 'r': 0.17181026476928488}, 'rouge-2': {'f': 0.09652137781110065, 'p': 0.1537783457326263, 'r': 0.07661630595190576}, 'rouge-l': {'f': 0.16347601644541387, 'p': 0.3032514812097066, 'r': 0.15353225018814678}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbnJMx3yOlAK",
        "colab_type": "text"
      },
      "source": [
        "## Task 2\n",
        "\n",
        "Add missing parts of [SummaRuNNer](https://arxiv.org/pdf/1611.04230.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kc0etEGfJ0p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a7174096-180c-4e96-f281-a1cba55a66ee"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "class SentenceEncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_dim, hidden_size, n_layers=3, dropout=0.3, bidirectional=True):\n",
        "        super().__init__()\n",
        "\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        assert hidden_size % num_directions == 0\n",
        "        hidden_size = hidden_size // num_directions\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.embedding_layer = nn.Embedding(input_size, embedding_dim)\n",
        "        self.rnn_layer = nn.LSTM(\n",
        "            embedding_dim,\n",
        "            hidden_size,\n",
        "            n_layers,\n",
        "            dropout=dropout,\n",
        "            bidirectional=bidirectional,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.dropout_layer = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, inputs, hidden=None):\n",
        "        embedded = self.embedding_layer(inputs)\n",
        "        outputs, _ = self.rnn_layer(embedded, hidden)\n",
        "        sentences_embeddings = torch.mean(outputs, 1)\n",
        "\n",
        "        return sentences_embeddings\n",
        "\n",
        "class SentenceTaggerRNN(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocabulary_size,\n",
        "        token_embedding_dim=256,\n",
        "        sentence_encoder_hidden_size=256,\n",
        "        absolute_position_hidden_size=15,\n",
        "        relative_position_hidden_size=15,\n",
        "        relative_groups=5,\n",
        "        hidden_size=256,\n",
        "        bidirectional=True,\n",
        "        sentence_encoder_n_layers=2,\n",
        "        sentence_encoder_dropout=0.3,\n",
        "        sentence_encoder_bidirectional=True,\n",
        "        n_layers=1,\n",
        "        dropout=0.3,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        assert hidden_size % num_directions == 0\n",
        "        assert 30 % relative_groups == 0\n",
        "        hidden_size = hidden_size // num_directions\n",
        "\n",
        "        self.relative_groups = relative_groups\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.absolute_position_emb = nn.Embedding(30, absolute_position_hidden_size)\n",
        "        self.relative_position_emb = nn.Embedding(30 // relative_groups, relative_position_hidden_size)\n",
        "\n",
        "        self.sentence_encoder = SentenceEncoderRNN(\n",
        "            vocabulary_size,\n",
        "            token_embedding_dim,\n",
        "            sentence_encoder_hidden_size,\n",
        "            sentence_encoder_n_layers,\n",
        "            sentence_encoder_dropout,\n",
        "            sentence_encoder_bidirectional\n",
        "        )\n",
        "        self.rnn_layer = nn.LSTM(\n",
        "            sentence_encoder_hidden_size,\n",
        "            hidden_size,\n",
        "            n_layers,\n",
        "            dropout=dropout,\n",
        "            bidirectional=bidirectional,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.dropout_layer = nn.Dropout(dropout)\n",
        "        self.content_linear_layer = nn.Linear(hidden_size * 2, 1)\n",
        "        self.document_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
        "        self.salience_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
        "        self.absolute_position_layer = nn.Linear(absolute_position_hidden_size, 1)\n",
        "        self.relative_position_layer = nn.Linear(relative_position_hidden_size, 1)\n",
        "        self.novelty_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
        "        self.tanh_layer = nn.Tanh()\n",
        "        self.bias = nn.Parameter(torch.empty((32, 30)).uniform_(-0.1, 0.1))\n",
        "\n",
        "    def forward(self, inputs, hidden=None):\n",
        "        batch_size, sentences_count, tokens_count = inputs.shape\n",
        "\n",
        "        inputs = inputs.reshape(-1, tokens_count)\n",
        "        embedded_sentences = self.sentence_encoder(inputs)\n",
        "        embedded_sentences = embedded_sentences.reshape(batch_size, sentences_count, -1)\n",
        "\n",
        "        outputs, _ = self.rnn_layer(embedded_sentences, hidden)\n",
        "        outputs = self.dropout_layer(outputs)\n",
        "\n",
        "        document_embedding = self.tanh_layer(self.document_linear_layer(torch.mean(outputs, 1)))\n",
        "\n",
        "        content = self.content_linear_layer(outputs).squeeze(2)\n",
        "\n",
        "        salience = torch.bmm(outputs, self.salience_linear_layer(document_embedding).unsqueeze(2)).squeeze(2)\n",
        "\n",
        "        abs_pos = np.array([np.arange(sentences_count) for _ in range(batch_size)])\n",
        "        abs_pos = torch.from_numpy(abs_pos).cuda()\n",
        "        abs_pos = self.absolute_position_layer(self.absolute_position_emb(abs_pos)).squeeze(2)\n",
        "\n",
        "        rel_pos = np.array([np.arange(sentences_count) // self.relative_groups for _ in range(batch_size)])\n",
        "        rel_pos = torch.from_numpy(rel_pos).cuda()\n",
        "        rel_pos = self.relative_position_layer(self.relative_position_emb(rel_pos)).squeeze(2)\n",
        "\n",
        "        out = content + salience + abs_pos + rel_pos + self.bias\n",
        "     \n",
        "        novelty = []\n",
        "        for i in range(batch_size):\n",
        "            tmp = []\n",
        "            s = torch.zeros((1, outputs.shape[2])).cuda()\n",
        "\n",
        "            for j in range(sentences_count):\n",
        "                nov = self.novelty_linear_layer(self.tanh_layer(s)) @ outputs[i][j]\n",
        "                s += outputs[i][j] * torch.sigmoid(out[i][j] - nov[0])\n",
        "                tmp.append(nov)\n",
        "\n",
        "            novelty.append(torch.cuda.FloatTensor(tmp))\n",
        "\n",
        "        return out - torch.cat(novelty).view(batch_size, -1)\n",
        "\n",
        "model = SentenceTaggerRNN(vocabulary.size())\n",
        "train_model(\n",
        "    model,\n",
        "    ext_train_records,\n",
        "    ext_val_records,\n",
        "    vocabulary,\n",
        "    bpe_processor,\n",
        "    device_name=\"cuda\",\n",
        "    batch_size=32,\n",
        "    epochs_count=5,\n",
        "    loss_every_nsteps=16\n",
        ")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Trainable params: 5317629\n",
            "Epoch = 0, Avg Train Loss = 0.3628, Avg val loss = 0.2749, Time = 24.34s\n",
            "Epoch = 0, Avg Train Loss = 0.2575, Avg val loss = 0.2905, Time = 23.82s\n",
            "Epoch = 0, Avg Train Loss = 0.2538, Avg val loss = 0.2757, Time = 23.92s\n",
            "Epoch = 0, Avg Train Loss = 0.2494, Avg val loss = 0.2444, Time = 23.91s\n",
            "Epoch = 0, Avg Train Loss = 0.2406, Avg val loss = 0.2515, Time = 23.83s\n",
            "Epoch = 0, Avg Train Loss = 0.2396, Avg val loss = 0.2658, Time = 24.04s\n",
            "Epoch = 0, Avg Train Loss = 0.2300, Avg val loss = 0.2025, Time = 23.99s\n",
            "Epoch = 0, Avg Train Loss = 0.2358, Avg val loss = 0.2474, Time = 24.24s\n",
            "Epoch = 0, Avg Train Loss = 0.2415, Avg val loss = 0.2192, Time = 24.24s\n",
            "Epoch = 0, Avg Train Loss = 0.2294, Avg val loss = 0.1945, Time = 24.26s\n",
            "Epoch = 0, Avg Train Loss = 0.2295, Avg val loss = 0.2269, Time = 24.31s\n",
            "Epoch = 0, Avg Train Loss = 0.2450, Avg val loss = 0.2581, Time = 24.10s\n",
            "Epoch = 0, Avg Train Loss = 0.2279, Avg val loss = 0.2545, Time = 24.22s\n",
            "Epoch = 0, Avg Train Loss = 0.2263, Avg val loss = 0.2467, Time = 24.10s\n",
            "Epoch = 0, Avg Train Loss = 0.2324, Avg val loss = 0.2262, Time = 24.09s\n",
            "Epoch = 0, Avg Train Loss = 0.2308, Avg val loss = 0.2486, Time = 24.11s\n",
            "Epoch = 0, Avg Train Loss = 0.2232, Avg val loss = 0.2332, Time = 24.09s\n",
            "Epoch = 0, Avg Train Loss = 0.2331, Avg val loss = 0.2381, Time = 24.20s\n",
            "Epoch = 0, Avg Train Loss = 0.2245, Avg val loss = 0.2373, Time = 24.03s\n",
            "Epoch = 0, Avg Train Loss = 0.2172, Avg val loss = 0.2047, Time = 24.06s\n",
            "Epoch = 0, Avg Train Loss = 0.2293, Avg val loss = 0.2666, Time = 24.03s\n",
            "Epoch = 0, Avg Train Loss = 0.2236, Avg val loss = 0.2502, Time = 24.07s\n",
            "Epoch = 0, Avg Train Loss = 0.2247, Avg val loss = 0.2577, Time = 23.99s\n",
            "Epoch = 0, Avg Train Loss = 0.2387, Avg val loss = 0.2555, Time = 24.18s\n",
            "Epoch = 0, Avg Train Loss = 0.2276, Avg val loss = 0.2155, Time = 24.33s\n",
            "Epoch = 0, Avg Train Loss = 0.2269, Avg val loss = 0.2294, Time = 24.30s\n",
            "Epoch = 0, Avg Train Loss = 0.2206, Avg val loss = 0.2295, Time = 24.33s\n",
            "Epoch = 0, Avg Train Loss = 0.2193, Avg val loss = 0.2213, Time = 24.24s\n",
            "Epoch = 0, Avg Train Loss = 0.2300, Avg val loss = 0.2459, Time = 24.43s\n",
            "Epoch = 0, Avg Train Loss = 0.2228, Avg val loss = 0.2712, Time = 24.15s\n",
            "Epoch = 0, Avg Train Loss = 0.2285, Avg val loss = 0.2575, Time = 24.28s\n",
            "\n",
            "\n",
            "Epoch = 1, Avg Train Loss = 0.2283, Avg val loss = 0.2457, Time = 24.58s\n",
            "Epoch = 1, Avg Train Loss = 0.2143, Avg val loss = 0.2411, Time = 24.27s\n",
            "Epoch = 1, Avg Train Loss = 0.2202, Avg val loss = 0.2595, Time = 24.22s\n",
            "Epoch = 1, Avg Train Loss = 0.2302, Avg val loss = 0.2485, Time = 24.30s\n",
            "Epoch = 1, Avg Train Loss = 0.2231, Avg val loss = 0.2856, Time = 24.20s\n",
            "Epoch = 1, Avg Train Loss = 0.2245, Avg val loss = 0.2578, Time = 24.26s\n",
            "Epoch = 1, Avg Train Loss = 0.2262, Avg val loss = 0.2659, Time = 24.25s\n",
            "Epoch = 1, Avg Train Loss = 0.2213, Avg val loss = 0.2548, Time = 24.21s\n",
            "Epoch = 1, Avg Train Loss = 0.2214, Avg val loss = 0.2579, Time = 24.24s\n",
            "Epoch = 1, Avg Train Loss = 0.2206, Avg val loss = 0.2646, Time = 24.21s\n",
            "Epoch = 1, Avg Train Loss = 0.2234, Avg val loss = 0.2601, Time = 24.18s\n",
            "Epoch = 1, Avg Train Loss = 0.2147, Avg val loss = 0.2547, Time = 24.05s\n",
            "Epoch = 1, Avg Train Loss = 0.2159, Avg val loss = 0.2377, Time = 24.16s\n",
            "Epoch = 1, Avg Train Loss = 0.2177, Avg val loss = 0.2402, Time = 24.39s\n",
            "Epoch = 1, Avg Train Loss = 0.2177, Avg val loss = 0.2816, Time = 24.10s\n",
            "Epoch = 1, Avg Train Loss = 0.2244, Avg val loss = 0.2521, Time = 24.12s\n",
            "Epoch = 1, Avg Train Loss = 0.2138, Avg val loss = 0.2487, Time = 24.32s\n",
            "Epoch = 1, Avg Train Loss = 0.2201, Avg val loss = 0.2442, Time = 24.20s\n",
            "Epoch = 1, Avg Train Loss = 0.2225, Avg val loss = 0.2752, Time = 24.13s\n",
            "Epoch = 1, Avg Train Loss = 0.2145, Avg val loss = 0.2324, Time = 24.13s\n",
            "Epoch = 1, Avg Train Loss = 0.2152, Avg val loss = 0.2504, Time = 24.22s\n",
            "Epoch = 1, Avg Train Loss = 0.2168, Avg val loss = 0.2506, Time = 24.09s\n",
            "Epoch = 1, Avg Train Loss = 0.2129, Avg val loss = 0.2303, Time = 24.37s\n",
            "Epoch = 1, Avg Train Loss = 0.2154, Avg val loss = 0.2518, Time = 24.23s\n",
            "Epoch = 1, Avg Train Loss = 0.2246, Avg val loss = 0.2587, Time = 24.21s\n",
            "Epoch = 1, Avg Train Loss = 0.2206, Avg val loss = 0.2803, Time = 24.13s\n",
            "Epoch = 1, Avg Train Loss = 0.2103, Avg val loss = 0.2326, Time = 24.26s\n",
            "Epoch = 1, Avg Train Loss = 0.2184, Avg val loss = 0.2778, Time = 24.17s\n",
            "Epoch = 1, Avg Train Loss = 0.2150, Avg val loss = 0.2474, Time = 24.26s\n",
            "Epoch = 1, Avg Train Loss = 0.2147, Avg val loss = 0.2516, Time = 24.44s\n",
            "Epoch = 1, Avg Train Loss = 0.2193, Avg val loss = 0.2705, Time = 24.53s\n",
            "\n",
            "\n",
            "Epoch = 2, Avg Train Loss = 0.2279, Avg val loss = 0.2773, Time = 24.62s\n",
            "Epoch = 2, Avg Train Loss = 0.2038, Avg val loss = 0.2517, Time = 24.40s\n",
            "Epoch = 2, Avg Train Loss = 0.2120, Avg val loss = 0.2916, Time = 24.26s\n",
            "Epoch = 2, Avg Train Loss = 0.2081, Avg val loss = 0.2345, Time = 24.15s\n",
            "Epoch = 2, Avg Train Loss = 0.2067, Avg val loss = 0.2501, Time = 24.34s\n",
            "Epoch = 2, Avg Train Loss = 0.2047, Avg val loss = 0.2779, Time = 24.21s\n",
            "Epoch = 2, Avg Train Loss = 0.2085, Avg val loss = 0.2559, Time = 24.21s\n",
            "Epoch = 2, Avg Train Loss = 0.2108, Avg val loss = 0.2731, Time = 24.04s\n",
            "Epoch = 2, Avg Train Loss = 0.2066, Avg val loss = 0.2743, Time = 24.18s\n",
            "Epoch = 2, Avg Train Loss = 0.2024, Avg val loss = 0.2625, Time = 24.12s\n",
            "Epoch = 2, Avg Train Loss = 0.2095, Avg val loss = 0.2872, Time = 24.16s\n",
            "Epoch = 2, Avg Train Loss = 0.2061, Avg val loss = 0.2318, Time = 24.31s\n",
            "Epoch = 2, Avg Train Loss = 0.1999, Avg val loss = 0.3158, Time = 24.16s\n",
            "Epoch = 2, Avg Train Loss = 0.2061, Avg val loss = 0.2533, Time = 24.14s\n",
            "Epoch = 2, Avg Train Loss = 0.2111, Avg val loss = 0.2866, Time = 24.26s\n",
            "Epoch = 2, Avg Train Loss = 0.2042, Avg val loss = 0.2383, Time = 24.23s\n",
            "Epoch = 2, Avg Train Loss = 0.2124, Avg val loss = 0.2956, Time = 24.40s\n",
            "Epoch = 2, Avg Train Loss = 0.2170, Avg val loss = 0.2681, Time = 24.31s\n",
            "Epoch = 2, Avg Train Loss = 0.2146, Avg val loss = 0.2832, Time = 24.25s\n",
            "Epoch = 2, Avg Train Loss = 0.2076, Avg val loss = 0.2842, Time = 24.25s\n",
            "Epoch = 2, Avg Train Loss = 0.2101, Avg val loss = 0.2369, Time = 24.30s\n",
            "Epoch = 2, Avg Train Loss = 0.2096, Avg val loss = 0.2901, Time = 24.22s\n",
            "Epoch = 2, Avg Train Loss = 0.1975, Avg val loss = 0.2671, Time = 24.14s\n",
            "Epoch = 2, Avg Train Loss = 0.2066, Avg val loss = 0.2993, Time = 24.17s\n",
            "Epoch = 2, Avg Train Loss = 0.2098, Avg val loss = 0.2319, Time = 24.32s\n",
            "Epoch = 2, Avg Train Loss = 0.2062, Avg val loss = 0.2443, Time = 24.29s\n",
            "Epoch = 2, Avg Train Loss = 0.2068, Avg val loss = 0.2361, Time = 24.39s\n",
            "Epoch = 2, Avg Train Loss = 0.2083, Avg val loss = 0.2356, Time = 24.28s\n",
            "Epoch = 2, Avg Train Loss = 0.2011, Avg val loss = 0.2227, Time = 24.25s\n",
            "Epoch = 2, Avg Train Loss = 0.2031, Avg val loss = 0.2595, Time = 24.11s\n",
            "Epoch = 2, Avg Train Loss = 0.2109, Avg val loss = 0.2497, Time = 24.18s\n",
            "\n",
            "\n",
            "Epoch = 3, Avg Train Loss = 0.2028, Avg val loss = 0.2492, Time = 24.78s\n",
            "Epoch = 3, Avg Train Loss = 0.1758, Avg val loss = 0.2490, Time = 24.50s\n",
            "Epoch = 3, Avg Train Loss = 0.1808, Avg val loss = 0.2859, Time = 24.26s\n",
            "Epoch = 3, Avg Train Loss = 0.1842, Avg val loss = 0.2787, Time = 24.30s\n",
            "Epoch = 3, Avg Train Loss = 0.1890, Avg val loss = 0.2915, Time = 24.30s\n",
            "Epoch = 3, Avg Train Loss = 0.1824, Avg val loss = 0.3579, Time = 24.32s\n",
            "Epoch = 3, Avg Train Loss = 0.1898, Avg val loss = 0.3027, Time = 24.30s\n",
            "Epoch = 3, Avg Train Loss = 0.1883, Avg val loss = 0.2550, Time = 24.09s\n",
            "Epoch = 3, Avg Train Loss = 0.1994, Avg val loss = 0.3334, Time = 24.32s\n",
            "Epoch = 3, Avg Train Loss = 0.1856, Avg val loss = 0.2283, Time = 24.14s\n",
            "Epoch = 3, Avg Train Loss = 0.1925, Avg val loss = 0.2794, Time = 24.13s\n",
            "Epoch = 3, Avg Train Loss = 0.1981, Avg val loss = 0.2898, Time = 24.24s\n",
            "Epoch = 3, Avg Train Loss = 0.1908, Avg val loss = 0.2569, Time = 24.23s\n",
            "Epoch = 3, Avg Train Loss = 0.1864, Avg val loss = 0.2771, Time = 24.17s\n",
            "Epoch = 3, Avg Train Loss = 0.1964, Avg val loss = 0.2585, Time = 24.15s\n",
            "Epoch = 3, Avg Train Loss = 0.1795, Avg val loss = 0.2602, Time = 24.09s\n",
            "Epoch = 3, Avg Train Loss = 0.1821, Avg val loss = 0.3419, Time = 24.13s\n",
            "Epoch = 3, Avg Train Loss = 0.1988, Avg val loss = 0.3055, Time = 24.36s\n",
            "Epoch = 3, Avg Train Loss = 0.1883, Avg val loss = 0.2612, Time = 24.38s\n",
            "Epoch = 3, Avg Train Loss = 0.1792, Avg val loss = 0.2662, Time = 24.06s\n",
            "Epoch = 3, Avg Train Loss = 0.1926, Avg val loss = 0.3328, Time = 24.13s\n",
            "Epoch = 3, Avg Train Loss = 0.1960, Avg val loss = 0.2825, Time = 24.16s\n",
            "Epoch = 3, Avg Train Loss = 0.1897, Avg val loss = 0.2729, Time = 24.18s\n",
            "Epoch = 3, Avg Train Loss = 0.1825, Avg val loss = 0.2463, Time = 24.18s\n",
            "Epoch = 3, Avg Train Loss = 0.1966, Avg val loss = 0.2802, Time = 24.08s\n",
            "Epoch = 3, Avg Train Loss = 0.1903, Avg val loss = 0.2544, Time = 24.17s\n",
            "Epoch = 3, Avg Train Loss = 0.1951, Avg val loss = 0.2739, Time = 24.18s\n",
            "Epoch = 3, Avg Train Loss = 0.1919, Avg val loss = 0.3134, Time = 24.11s\n",
            "Epoch = 3, Avg Train Loss = 0.1935, Avg val loss = 0.3117, Time = 24.15s\n",
            "Epoch = 3, Avg Train Loss = 0.1907, Avg val loss = 0.2768, Time = 24.11s\n",
            "Epoch = 3, Avg Train Loss = 0.1955, Avg val loss = 0.2410, Time = 24.14s\n",
            "\n",
            "\n",
            "Epoch = 4, Avg Train Loss = 0.1587, Avg val loss = 0.3342, Time = 24.89s\n",
            "Epoch = 4, Avg Train Loss = 0.1397, Avg val loss = 0.3190, Time = 24.22s\n",
            "Epoch = 4, Avg Train Loss = 0.1455, Avg val loss = 0.3682, Time = 24.05s\n",
            "Epoch = 4, Avg Train Loss = 0.1539, Avg val loss = 0.3621, Time = 24.31s\n",
            "Epoch = 4, Avg Train Loss = 0.1506, Avg val loss = 0.3162, Time = 24.41s\n",
            "Epoch = 4, Avg Train Loss = 0.1541, Avg val loss = 0.2976, Time = 24.21s\n",
            "Epoch = 4, Avg Train Loss = 0.1505, Avg val loss = 0.3164, Time = 24.18s\n",
            "Epoch = 4, Avg Train Loss = 0.1531, Avg val loss = 0.3371, Time = 24.15s\n",
            "Epoch = 4, Avg Train Loss = 0.1608, Avg val loss = 0.3265, Time = 24.34s\n",
            "Epoch = 4, Avg Train Loss = 0.1572, Avg val loss = 0.3333, Time = 24.21s\n",
            "Epoch = 4, Avg Train Loss = 0.1509, Avg val loss = 0.3653, Time = 24.20s\n",
            "Epoch = 4, Avg Train Loss = 0.1555, Avg val loss = 0.2865, Time = 24.23s\n",
            "Epoch = 4, Avg Train Loss = 0.1554, Avg val loss = 0.3439, Time = 24.18s\n",
            "Epoch = 4, Avg Train Loss = 0.1519, Avg val loss = 0.4132, Time = 24.21s\n",
            "Epoch = 4, Avg Train Loss = 0.1608, Avg val loss = 0.3574, Time = 24.41s\n",
            "Epoch = 4, Avg Train Loss = 0.1622, Avg val loss = 0.3447, Time = 24.31s\n",
            "Epoch = 4, Avg Train Loss = 0.1583, Avg val loss = 0.3380, Time = 24.31s\n",
            "Epoch = 4, Avg Train Loss = 0.1567, Avg val loss = 0.3247, Time = 24.17s\n",
            "Epoch = 4, Avg Train Loss = 0.1604, Avg val loss = 0.3544, Time = 24.28s\n",
            "Epoch = 4, Avg Train Loss = 0.1606, Avg val loss = 0.3146, Time = 24.18s\n",
            "Epoch = 4, Avg Train Loss = 0.1562, Avg val loss = 0.2955, Time = 24.51s\n",
            "Epoch = 4, Avg Train Loss = 0.1613, Avg val loss = 0.2741, Time = 24.42s\n",
            "Epoch = 4, Avg Train Loss = 0.1598, Avg val loss = 0.3519, Time = 24.36s\n",
            "Epoch = 4, Avg Train Loss = 0.1581, Avg val loss = 0.3533, Time = 24.29s\n",
            "Epoch = 4, Avg Train Loss = 0.1603, Avg val loss = 0.3219, Time = 24.16s\n",
            "Epoch = 4, Avg Train Loss = 0.1605, Avg val loss = 0.3198, Time = 24.39s\n",
            "Epoch = 4, Avg Train Loss = 0.1625, Avg val loss = 0.3195, Time = 24.34s\n",
            "Epoch = 4, Avg Train Loss = 0.1649, Avg val loss = 0.3153, Time = 24.21s\n",
            "Epoch = 4, Avg Train Loss = 0.1580, Avg val loss = 0.3373, Time = 24.15s\n",
            "Epoch = 4, Avg Train Loss = 0.1635, Avg val loss = 0.3521, Time = 24.17s\n",
            "Epoch = 4, Avg Train Loss = 0.1616, Avg val loss = 0.3940, Time = 24.10s\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acGCp-CRtpCi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "2e0329b8-67d2-48b6-af80-f319a54294d0"
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "references = []\n",
        "predictions = []\n",
        "for step, batch in enumerate(BatchIterator(ext_test_records, vocabulary, 32, bpe_processor, device=device)):\n",
        "    logits = model(batch[\"inputs\"])\n",
        "    records = batch[\"records\"]\n",
        "\n",
        "    for record, record_logits in zip(records, logits):\n",
        "        sentences = record[\"sentences\"]\n",
        "\n",
        "        predicted_summary = []\n",
        "        for i, logit in enumerate(record_logits):\n",
        "            if logit > 0.0:\n",
        "                predicted_summary.append(sentences[i])\n",
        "\n",
        "        if not predicted_summary:\n",
        "            predicted_summary.append(sentences[torch.max(record_logits, dim=0)[1].item()])\n",
        "\n",
        "        predicted_summary = \" \".join(predicted_summary)\n",
        "        references.append(record[\"summary\"].lower())\n",
        "        predictions.append(predicted_summary)\n",
        "\n",
        "calc_scores(references, predictions)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count: 1024\n",
            "Ref: компания apple продолжает осваивать все новые рынки — если верить инсайдерам, «яблоко» готовит к выпуску игровой компьютер, предназначенный специально для киберспортсменов. стоимость такого устройства предположительно составит $5 тыс., а увидеть его можно будет на презентации wwdc 2020 летом следующего года.\n",
            "Hyp: компания apple , запустившая в этом году игровой сервис apple arcade, планирует продолжить свою экспансию на рынок гейминга.\n",
            "BLEU:  0.24098685115950752\n",
            "ROUGE:  {'rouge-1': {'f': 0.20366603549220438, 'p': 0.30138822885618005, 'r': 0.16871960242354342}, 'rouge-2': {'f': 0.08428669086759899, 'p': 0.126893012485077, 'r': 0.07016954171489367}, 'rouge-l': {'f': 0.15845245948232436, 'p': 0.273405996643831, 'r': 0.1523603019747474}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1I9q9iGUqB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
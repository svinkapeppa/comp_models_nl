{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Морфология\n",
    "\n",
    "Здесь мы познакомимся с двумя мофрологическими анализоторами: `pymorphy` и `mystem`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = 'Гло́кая ку́здра ште́ко будлану́ла бо́кра и курдя́чит бокрёнка'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. MyStem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analyzer\n",
    "# `entire_input` -- copy entire input to output\n",
    "# `disambiguation` -- apply disambiguation\n",
    "mystem_analyzer = Mystem(entire_input=False, disambiguation=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Две основные функции `Mystem`:\n",
    "* Проводить морфологический анализ\n",
    "* Приводить слова в начальную форму"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_result = mystem_analyzer.analyze(sample_text)\n",
    "mystem_lemmas = mystem_analyzer.lemmatize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Original: Гло́кая ку́здра ште́ко будлану́ла бо́кра и курдя́чит бокрёнка\n",
      "After lemmatization: глокая куздра штеко будлануть бокра и курдячить бокренка\n"
     ]
    }
   ],
   "source": [
    "# Let's compare original text and the lemmatized one\n",
    "print('           Original: {}'.format(sample_text))\n",
    "print('After lemmatization: {}'.format(' '.join(mystem_lemmas)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гло́кая\n",
      "\t{'lex': 'глокая', 'wt': 0.3605448306, 'qual': 'bastard', 'gr': 'S,ед,жен,неод=им'}\n",
      "\t{'lex': 'глокать', 'wt': 0.3605448306, 'qual': 'bastard', 'gr': 'V,несов=непрош,деепр,пе'}\n",
      "\t{'lex': 'глокая', 'wt': 0.1038369089, 'qual': 'bastard', 'gr': 'S,жен,од=им,ед'}\n",
      "\t{'lex': 'глокай', 'wt': 0.09304980189, 'qual': 'bastard', 'gr': 'S,муж,неод=род,ед'}\n",
      "\t{'lex': 'глокать', 'wt': 0.03306575492, 'qual': 'bastard', 'gr': 'V,несов,нп=непрош,деепр'}\n",
      "\t{'lex': 'глокий', 'wt': 0.01624944061, 'qual': 'bastard', 'gr': 'A=им,ед,полн,жен'}\n",
      "\t{'lex': 'глокать', 'wt': 0.01512198243, 'qual': 'bastard', 'gr': 'V,несов,пе=непрош,деепр'}\n",
      "\t{'lex': 'глокий', 'wt': 0.01077529974, 'qual': 'bastard', 'gr': 'A=им,ед,полн,жен'}\n",
      "\t{'lex': 'глокать', 'wt': 0.006811153609, 'qual': 'bastard', 'gr': 'V,нп=непрош,деепр,несов'}\n",
      "ку́здра\n",
      "\t{'lex': 'куздра', 'wt': 0.6292693615, 'qual': 'bastard', 'gr': 'S,ед,жен,неод=им'}\n",
      "\t{'lex': 'куздра', 'wt': 0.3707306087, 'qual': 'bastard', 'gr': 'S,гео,жен,неод=им,ед'}\n",
      "ште́ко\n",
      "\t{'lex': 'штеко', 'wt': 0.32176736, 'qual': 'bastard', 'gr': 'S,имя,мж,од=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}\n",
      "\t{'lex': 'штеко', 'wt': 0.2574119866, 'qual': 'bastard', 'gr': 'ADV='}\n",
      "\t{'lex': 'штеко', 'wt': 0.1608460993, 'qual': 'bastard', 'gr': 'S,сред,неод=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}\n",
      "\t{'lex': 'штеко', 'wt': 0.08253134042, 'qual': 'bastard', 'gr': 'S,сред,неод=(вин,ед|им,ед)'}\n",
      "\t{'lex': 'штеко', 'wt': 0.07936871052, 'qual': 'bastard', 'gr': 'S,ед,сред,неод=(вин|им)'}\n",
      "\t{'lex': 'штеко', 'wt': 0.0321521163, 'qual': 'bastard', 'gr': 'S,имя,муж,од=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}\n",
      "\t{'lex': 'штеко', 'wt': 0.03210293502, 'qual': 'bastard', 'gr': 'S,фам,мж,од=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}\n",
      "\t{'lex': 'штеко', 'wt': 0.0320860967, 'qual': 'bastard', 'gr': 'S,гео,ед,муж,неод=(пр|вин|дат|род|твор|им)'}\n",
      "\t{'lex': 'штекий', 'wt': 0.001720046741, 'qual': 'bastard', 'gr': 'A=ед,кр,сред'}\n",
      "\t{'lex': 'штекий', 'wt': 1.332032934e-05, 'qual': 'bastard', 'gr': 'A=ед,кр,сред'}\n",
      "\t{'lex': 'штеко', 'wt': 0, 'qual': 'bastard', 'gr': 'S,имя,ед,муж,од=им'}\n",
      "будлану́ла\n",
      "\t{'lex': 'будлануть', 'wt': 0.2884335816, 'qual': 'bastard', 'gr': 'V,обсц,сов=прош,ед,изъяв,жен'}\n",
      "\t{'lex': 'будлануть', 'wt': 0.2884335816, 'qual': 'bastard', 'gr': 'V,разг,обсц,сов=прош,ед,изъяв,жен'}\n",
      "\t{'lex': 'будланула', 'wt': 0.09985378385, 'qual': 'bastard', 'gr': 'S,имя,жен,од=им,ед'}\n",
      "\t{'lex': 'будлануть', 'wt': 0.056951534, 'qual': 'bastard', 'gr': 'V,сов,пе=прош,ед,изъяв,жен'}\n",
      "\t{'lex': 'будлануть', 'wt': 0.05212627351, 'qual': 'bastard', 'gr': 'V,сов,пе=прош,ед,изъяв,жен'}\n",
      "\t{'lex': 'будлануть', 'wt': 0.04770114273, 'qual': 'bastard', 'gr': 'V,сов,нп=прош,ед,изъяв,жен'}\n",
      "\t{'lex': 'будлануть', 'wt': 0.04683850333, 'qual': 'bastard', 'gr': 'V,сов,пе=прош,ед,изъяв,жен'}\n",
      "\t{'lex': 'будланула', 'wt': 0.04299689457, 'qual': 'bastard', 'gr': 'S,жен,неод=им,ед'}\n",
      "\t{'lex': 'будланул', 'wt': 0.03753661737, 'qual': 'bastard', 'gr': 'S,муж,од=(вин,ед|род,ед)'}\n",
      "\t{'lex': 'будлануть', 'wt': 0.02766311727, 'qual': 'bastard', 'gr': 'V,сов,нп=прош,ед,изъяв,жен'}\n",
      "\t{'lex': 'будланывать', 'wt': 0.01146493386, 'qual': 'bastard', 'gr': 'V,пе=прош,ед,изъяв,жен,сов'}\n",
      "бо́кра\n",
      "\t{'lex': 'бокра', 'wt': 0.8898982406, 'qual': 'bastard', 'gr': 'S,ед,жен,неод=им'}\n",
      "\t{'lex': 'бокрый', 'wt': 0.1101017669, 'qual': 'bastard', 'gr': 'A=ед,кр,жен'}\n",
      "и\n",
      "\t{'lex': 'и', 'wt': 0.9999770522, 'gr': 'CONJ='}\n",
      "\t{'lex': 'и', 'wt': 1.020511536e-05, 'gr': 'INTJ='}\n",
      "\t{'lex': 'и', 'wt': 6.379604656e-06, 'gr': 'S,сокр=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}\n",
      "\t{'lex': 'и', 'wt': 6.37957055e-06, 'gr': 'PART='}\n",
      "курдя́чит\n",
      "\t{'lex': 'курдячить', 'wt': 0.5, 'qual': 'bastard', 'gr': 'V,обсц,сов,пе=непрош,ед,изъяв,3-л'}\n",
      "\t{'lex': 'курдячить', 'wt': 0.5, 'qual': 'bastard', 'gr': 'V,обсц,несов,пе=непрош,ед,изъяв,3-л'}\n",
      "бокрёнка\n",
      "\t{'lex': 'бокренка', 'wt': 0.2200160921, 'qual': 'bastard', 'gr': 'S,имя,жен,од=им,ед'}\n",
      "\t{'lex': 'бокренок', 'wt': 0.1651664227, 'qual': 'bastard', 'gr': 'S,муж,неод=род,ед'}\n",
      "\t{'lex': 'бокренка', 'wt': 0.139254272, 'qual': 'bastard', 'gr': 'S,жен,од=им,ед'}\n",
      "\t{'lex': 'бокренка', 'wt': 0.1240808442, 'qual': 'bastard', 'gr': 'S,жен,неод=им,ед'}\n",
      "\t{'lex': 'бокренок', 'wt': 0.1205990389, 'qual': 'bastard', 'gr': 'S,муж,неод=род,ед'}\n",
      "\t{'lex': 'бокренок', 'wt': 0.09129371494, 'qual': 'bastard', 'gr': 'S,муж,од=(вин,ед|род,ед)'}\n",
      "\t{'lex': 'бокренка', 'wt': 0.07074299455, 'qual': 'bastard', 'gr': 'S,имя,мж,од=им,ед'}\n",
      "\t{'lex': 'бокренк', 'wt': 0.06884660572, 'qual': 'bastard', 'gr': 'S,имя,муж,од=(вин,ед|род,ед)'}\n"
     ]
    }
   ],
   "source": [
    "# Result of morphological analysis\n",
    "for word in mystem_result:\n",
    "    print(word['text'])\n",
    "    for res in word['analysis']:\n",
    "        print('\\t{}'.format(repr(res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим теперь анализатор со снятием омонимии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_analyzer2 = Mystem(entire_input=False, disambiguation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_result2 = mystem_analyzer2.analyze(sample_text)\n",
    "mystem_lemmas2 = mystem_analyzer2.lemmatize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Гло́кая ку́здра ште́ко будлану́ла бо́кра и курдя́чит бокрёнка\n",
      "\n",
      "\tAfter lemmatization\n",
      "Without disambiguation    With disambiguation\n",
      "------------------------  ---------------------\n",
      "глокая                    глокай\n",
      "куздра                    куздра\n",
      "штеко                     штеко\n",
      "будлануть                 будланул\n",
      "бокра                     бокра\n",
      "и                         и\n",
      "курдячить                 курдячить\n",
      "бокренка                  бокренок\n"
     ]
    }
   ],
   "source": [
    "# Let's compare original text and two lemmatized variants\n",
    "print('Original: {}\\n'.format(sample_text))\n",
    "print('\\tAfter lemmatization')\n",
    "\n",
    "headers = ['Without disambiguation', 'With disambiguation']\n",
    "print(tabulate(zip(mystem_lemmas, mystem_lemmas2), headers=headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гло́кая\n",
      "\t{'lex': 'глокай', 'wt': 0.09304980189, 'qual': 'bastard', 'gr': 'S,муж,неод=род,ед'}\n",
      "ку́здра\n",
      "\t{'lex': 'куздра', 'wt': 0.6292693615, 'qual': 'bastard', 'gr': 'S,ед,жен,неод=им'}\n",
      "ште́ко\n",
      "\t{'lex': 'штеко', 'wt': 0.2574119866, 'qual': 'bastard', 'gr': 'ADV='}\n",
      "будлану́ла\n",
      "\t{'lex': 'будланул', 'wt': 0.03753661737, 'qual': 'bastard', 'gr': 'S,муж,од=(вин,ед|род,ед)'}\n",
      "бо́кра\n",
      "\t{'lex': 'бокра', 'wt': 0.8898982406, 'qual': 'bastard', 'gr': 'S,ед,жен,неод=им'}\n",
      "и\n",
      "\t{'lex': 'и', 'wt': 0.9999770522, 'gr': 'CONJ='}\n",
      "курдя́чит\n",
      "\t{'lex': 'курдячить', 'wt': 0.5, 'qual': 'bastard', 'gr': 'V,обсц,сов,пе=непрош,ед,изъяв,3-л'}\n",
      "бокрёнка\n",
      "\t{'lex': 'бокренок', 'wt': 0.1651664227, 'qual': 'bastard', 'gr': 'S,муж,неод=род,ед'}\n"
     ]
    }
   ],
   "source": [
    "# Result of morphological analysis\n",
    "for word in mystem_result2:\n",
    "    print(word['text'])\n",
    "    for res in word['analysis']:\n",
    "        print('\\t{}'.format(repr(res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблемы MyStem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "александра иванов пойти в кино\n",
      "александра иванов видеть в кино с кто-то\n",
      "воробей сегодня вставать не с тот нога\n"
     ]
    }
   ],
   "source": [
    "disambiguations = ['Александра Иванова пошла в кино',\n",
    "                   'Александра Иванова видели в кино с кем-то',\n",
    "                   'Воробьев сегодня встал не с той ноги']\n",
    "\n",
    "disambiguation_results = []\n",
    "for dis in disambiguations:\n",
    "    disambiguation_results.append(mystem_analyzer2.lemmatize(dis))\n",
    "    \n",
    "for res in disambiguation_results:\n",
    "    print(' '.join(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание\n",
    "Для того, чтобы наиграться с `MyStem`, предлагается написать методы, которые:\n",
    "* находят топ `n` лексем\n",
    "* находят слова с наибольшей и наименьшей энтропией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(text, n):\n",
    "    '''\n",
    "    :param text: input text in russian\n",
    "    :param n: number of most common words\n",
    "    :return: list of most common lexemas\n",
    "    '''\n",
    "    vocabulary = {}\n",
    "\n",
    "    analyzer = Mystem(entire_input=False, disambiguation=True)\n",
    "    result = analyzer.analyze(text)\n",
    "\n",
    "    for word in result:\n",
    "        if word['analysis'][0]['lex'] in vocabulary:\n",
    "            vocabulary[word['analysis'][0]['lex']] += 1\n",
    "        else:\n",
    "            vocabulary[word['analysis'][0]['lex']] = 1\n",
    "\n",
    "    return sorted(vocabulary.items(), key=lambda kv: -kv[1])[:n]\n",
    "\n",
    "def get_max_entropy_words(text, n):\n",
    "    '''\n",
    "    :param text: input text in russian\n",
    "    :param n: number of most words with maximum entropy\n",
    "    :return: list of words with entropies\n",
    "    '''\n",
    "    analyzer = Mystem(entire_input=False, disambiguation=True)\n",
    "    result = analyzer.analyze(text)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    scored_words = set([(word['analysis'][0]['lex'], word['analysis'][0]['wt'])\n",
    "                        for word in result])\n",
    "    \n",
    "    return sorted(scored_words, key=lambda kv: -kv[1])[:n]\n",
    "\n",
    "def get_min_entropy_words(text, n):\n",
    "    '''\n",
    "    :param text: input text in russian\n",
    "    :param n: number of most words with minimum entropy\n",
    "    :return: list of words with entropies\n",
    "    '''\n",
    "    analyzer = Mystem(entire_input=False, disambiguation=True)\n",
    "    result = analyzer.analyze(text)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    scored_words = set([(word['analysis'][0]['lex'], word['analysis'][0]['wt'])\n",
    "                        for word in result])\n",
    "    \n",
    "    return sorted(scored_words, key=lambda kv: kv[1])[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/text.txt', 'r') as file:\n",
    "    text = file.read().replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexema      Count\n",
      "--------  -------\n",
      "я              26\n",
      "и              22\n",
      "в              17\n",
      "быть           16\n",
      "на             16\n",
      "он             12\n",
      "не             11\n",
      "с              10\n",
      "но              9\n",
      "что             8\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(get_top_words(text, 10), headers=['Lexema', 'Count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexema        Entropy\n",
      "----------  ---------\n",
      "мой                 1\n",
      "стоять              1\n",
      "знать               1\n",
      "слово               1\n",
      "колыхаться          1\n",
      "нога                1\n",
      "открывать           1\n",
      "грузовик            1\n",
      "фартук              1\n",
      "удивляться          1\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(get_max_entropy_words(text, 10), headers=['Lexema', 'Entropy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexema          Entropy\n",
      "----------  -----------\n",
      "его         3.28409e-05\n",
      "было        0.0243193\n",
      "о           0.0261385\n",
      "немало      0.0286313\n",
      "одетый      0.0844251\n",
      "глупый      0.0897583\n",
      "разумеется  0.102032\n",
      "вокруг      0.224326\n",
      "тверская    0.296113\n",
      "то          0.30407\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(get_min_entropy_words(text, 10), headers=['Lexema', 'Entropy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pymorphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analyzer\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzer processes word by word\n",
    "pymorphy_results = map(lambda x: morph.parse(x), sample_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tWORD: гло́кая\n",
      "Lexema    Tag                                     Weight\n",
      "--------  ----------------------------------  ----------\n",
      "гло́кай    NOUN,anim,masc,Name sing,gent       0.333342\n",
      "гло́кай    NOUN,anim,masc,Name sing,accs       0.333342\n",
      "гло́кий    ADJF femn,sing,nomn                 0.308332\n",
      "гло́кий    NOUN,anim,femn,Sgtm,Surn sing,nomn  0.0214108\n",
      "гло́кать   GRND,impf,intr pres                 0.00357298\n",
      "\n",
      "\tWORD: ку́здра\n",
      "Lexema    Tag                                             Weight\n",
      "--------  --------------------------------------------  --------\n",
      "ку́здра    NOUN,inan,femn,Sgtm,Fixd,Abbr,Geox sing,nomn      0.15\n",
      "ку́здра    NOUN,inan,femn,Sgtm,Fixd,Abbr,Geox sing,gent      0.15\n",
      "ку́здра    NOUN,inan,femn,Sgtm,Fixd,Abbr,Geox sing,datv      0.15\n",
      "ку́здра    NOUN,inan,femn,Sgtm,Fixd,Abbr,Geox sing,accs      0.15\n",
      "ку́здра    NOUN,inan,femn,Sgtm,Fixd,Abbr,Geox sing,ablt      0.15\n",
      "ку́здра    NOUN,inan,femn,Sgtm,Fixd,Abbr,Geox sing,loct      0.15\n",
      "ку́здра    NOUN,inan,femn,Sgtm sing,nomn                     0.05\n",
      "ку́здра    NOUN,inan,femn,Sgtm,Geox sing,nomn                0.05\n",
      "\n",
      "\tWORD: ште́ко\n",
      "Lexema    Tag                                           Weight\n",
      "--------  ---------------------------------------  -----------\n",
      "ште́ко     NOUN,anim,GNdr,Ms-f,Fixd,Surn sing,nomn  0.0799503\n",
      "ште́ко     NOUN,anim,GNdr,Ms-f,Fixd,Surn sing,gent  0.0799503\n",
      "ште́ко     NOUN,anim,GNdr,Ms-f,Fixd,Surn sing,datv  0.0799503\n",
      "ште́ко     NOUN,anim,GNdr,Ms-f,Fixd,Surn sing,accs  0.0799503\n",
      "ште́ко     NOUN,anim,GNdr,Ms-f,Fixd,Surn sing,ablt  0.0799503\n",
      "ште́ко     NOUN,anim,GNdr,Ms-f,Fixd,Surn sing,loct  0.0799503\n",
      "ште́ко     NOUN,anim,GNdr,Ms-f,Fixd,Surn plur,nomn  0.0799503\n",
      "ште́ко     NOUN,anim,GNdr,Ms-f,Fixd,Surn plur,gent  0.0799503\n",
      "ште́ко     NOUN,anim,GNdr,Ms-f,Fixd,Surn plur,datv  0.0799503\n",
      "ште́ко     NOUN,anim,GNdr,Ms-f,Fixd,Surn plur,accs  0.0799503\n",
      "ште́ко     NOUN,anim,GNdr,Ms-f,Fixd,Surn plur,ablt  0.0799503\n",
      "ште́ко     NOUN,anim,GNdr,Ms-f,Fixd,Surn plur,loct  0.0799503\n",
      "ште́ко     ADVB                                     0.0194698\n",
      "ште́кий    ADJS neut,sing                           0.00787075\n",
      "ште́ко     ADJF,Fixd,Subx,Qual masc,sing,nomn       0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual masc,sing,gent       0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual masc,sing,datv       0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual masc,sing,accs       0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual masc,sing,ablt       0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual masc,sing,loct       0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual femn,sing,nomn       0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual femn,sing,gent       0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual femn,sing,datv       0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual femn,sing,accs       0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual femn,sing,ablt       0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual femn,sing,loct       0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual neut,sing,nomn       0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual neut,sing,gent       0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual neut,sing,datv       0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual neut,sing,accs       0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual neut,sing,ablt       0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual neut,sing,loct       0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual plur,nomn            0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual plur,gent            0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual plur,datv            0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual plur,accs            0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual plur,ablt            0.000552334\n",
      "ште́ко     ADJF,Fixd,Subx,Qual plur,loct            0.000552334\n",
      "\n",
      "\tWORD: будлану́ла\n",
      "Lexema      Tag                                     Weight\n",
      "----------  ----------------------------------  ----------\n",
      "будлану́ть   VERB,impf,tran femn,sing,past,indc  0.849908\n",
      "будлану́л    NOUN,inan,masc sing,gent            0.11236\n",
      "будлану́лый  ADJS femn,sing                      0.0362234\n",
      "будлану́ла   ADVB                                0.00150931\n",
      "\n",
      "\tWORD: бо́кра\n",
      "Lexema    Tag                         Weight\n",
      "--------  ------------------------  --------\n",
      "бо́кр      NOUN,inan,masc sing,gent  0.444444\n",
      "бо́кра     NOUN,inan,femn sing,nomn  0.444444\n",
      "бо́крый    ADJS,Qual femn,sing       0.111111\n",
      "\n",
      "\tWORD: и\n",
      "Lexema       Tag                                   Weight\n",
      "-----------  ----------------------------------  --------\n",
      "и            CONJ                                0.997671\n",
      "и            INTJ                                0.000436\n",
      "и            PRCL                                0.000145\n",
      "исполняющий  NOUN,anim,masc,Fixd,Abbr sing,nomn  0.000145\n",
      "исполняющий  NOUN,anim,masc,Fixd,Abbr sing,gent  0.000145\n",
      "исполняющий  NOUN,anim,masc,Fixd,Abbr sing,datv  0.000145\n",
      "исполняющий  NOUN,anim,masc,Fixd,Abbr sing,accs  0.000145\n",
      "исполняющий  NOUN,anim,masc,Fixd,Abbr sing,ablt  0.000145\n",
      "исполняющий  NOUN,anim,masc,Fixd,Abbr sing,loct  0.000145\n",
      "исполняющий  NOUN,anim,masc,Fixd,Abbr plur,nomn  0.000145\n",
      "исполняющий  NOUN,anim,masc,Fixd,Abbr plur,gent  0.000145\n",
      "исполняющий  NOUN,anim,masc,Fixd,Abbr plur,datv  0.000145\n",
      "исполняющий  NOUN,anim,masc,Fixd,Abbr plur,accs  0.000145\n",
      "исполняющий  NOUN,anim,masc,Fixd,Abbr plur,ablt  0.000145\n",
      "исполняющий  NOUN,anim,masc,Fixd,Abbr plur,loct  0.000145\n",
      "\n",
      "\tWORD: курдя́чит\n",
      "Lexema      Tag                                          Weight\n",
      "----------  ---------------------------------------  ----------\n",
      "курдя́чить   VERB,perf,tran sing,3per,futr,indc       0.941176\n",
      "курдя́читый  ADJS,Qual masc,sing                      0.00735294\n",
      "курдя́чит    NOUN,anim,femn,Sgtm,Fixd,Name sing,nomn  0.00735294\n",
      "курдя́чит    NOUN,anim,femn,Sgtm,Fixd,Name sing,gent  0.00735294\n",
      "курдя́чит    NOUN,anim,femn,Sgtm,Fixd,Name sing,datv  0.00735294\n",
      "курдя́чит    NOUN,anim,femn,Sgtm,Fixd,Name sing,accs  0.00735294\n",
      "курдя́чит    NOUN,anim,femn,Sgtm,Fixd,Name sing,ablt  0.00735294\n",
      "курдя́чит    NOUN,anim,femn,Sgtm,Fixd,Name sing,loct  0.00735294\n",
      "курдя́читый  ADJS masc,sing                           0.00735294\n",
      "\n",
      "\tWORD: бокрёнка\n",
      "Lexema    Tag                         Weight\n",
      "--------  ------------------------  --------\n",
      "бокрёнок  NOUN,anim,masc sing,gent       0.5\n",
      "бокрёнок  NOUN,anim,masc sing,accs       0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for word_result in pymorphy_results:\n",
    "    print('\\tWORD: {}'.format(word_result[0].word))\n",
    "\n",
    "    results = []\n",
    "    for res in word_result:\n",
    "        results.append((res.normal_form, res.tag, res.score))\n",
    "\n",
    "    print(tabulate(results, headers=['Lexema', 'Tag', 'Weight']))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличие от `mystem` можно получать лексему и склонять слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexema     POS\n",
      "---------  -----\n",
      "градус     NOUN\n",
      "градуса    NOUN\n",
      "градусу    NOUN\n",
      "градус     NOUN\n",
      "градусом   NOUN\n",
      "градусе    NOUN\n",
      "градусы    NOUN\n",
      "градусов   NOUN\n",
      "градусам   NOUN\n",
      "градусы    NOUN\n",
      "градусами  NOUN\n",
      "градусах   NOUN\n"
     ]
    }
   ],
   "source": [
    "parsed = morph.parse('градус')[0]\n",
    "\n",
    "results = []\n",
    "for form in parsed.lexeme:\n",
    "    results.append((form.word, form.tag.POS))\n",
    "\n",
    "print(tabulate(results, headers=['Lexema', 'POS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: градусе\n",
      "1 градус\n",
      "2 градуса\n",
      "5 градусов\n"
     ]
    }
   ],
   "source": [
    "print('WORD: {}'.format(parsed.inflect({'loct'}).word))\n",
    "\n",
    "for number in [1, 2, 5]:\n",
    "    print('{} {}'.format(number, parsed.make_agree_with_number(number).word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание \n",
    "\n",
    "С помощью `pymorphy` на тексте получить:\n",
    "- Распределение по частям речи\n",
    "- Для части речи вывести топ `n` лексем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_distribution(text, pos=None):\n",
    "    '''\n",
    "    :param: text: input text in russian\n",
    "    :param: pos: list of interested pos, if None - all are interesting \n",
    "    :return: dict of pos - probability\n",
    "    '''\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "    tags = [morph.parse(word)[0].tag.POS for word in text.split()]\n",
    "\n",
    "    distribution = {}\n",
    "    for tag in tags:\n",
    "        # Pretty\n",
    "        if tag is None:\n",
    "            tag = 'None'\n",
    "\n",
    "        if tag not in distribution:\n",
    "            distribution[tag] = 1\n",
    "        else:\n",
    "            distribution[tag] += 1\n",
    "    \n",
    "    for key in distribution.keys():\n",
    "        distribution[key] /= len(tags)\n",
    "    \n",
    "    if pos is not None:\n",
    "        tmp = {}\n",
    "        \n",
    "        for tag in pos:\n",
    "            # Compability with pretty formatting above\n",
    "            if tag is None:\n",
    "                tag = 'None'\n",
    "\n",
    "            if tag in distribution:\n",
    "                tmp[tag] = distribution[tag]\n",
    "            else:\n",
    "                tmp[tag] = 0\n",
    "\n",
    "        return tmp\n",
    "\n",
    "    return distribution\n",
    "\n",
    "def get_top_pos_words(text, pos, n):\n",
    "    '''\n",
    "    :param text: input text in russian\n",
    "    :param pos: part of speech \n",
    "    :param n: number of most common words\n",
    "    :return: list of most common lexemas with selected pos\n",
    "    '''\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    \n",
    "    parsed = [(morph.parse(word)[0].word, morph.parse(word)[0].tag.POS)\n",
    "              for word in text.split()]\n",
    "    selected = [word[0] for word in parsed if word[1] == pos]\n",
    "    \n",
    "    vocabulary = {}\n",
    "    \n",
    "    for word in selected:\n",
    "        if word not in vocabulary:\n",
    "            vocabulary[word] = 1\n",
    "        else:\n",
    "            vocabulary[word] += 1\n",
    "\n",
    "    return sorted(vocabulary.items(), key=lambda kv: -kv[1])[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS      Distribution\n",
      "-----  --------------\n",
      "NOUN         0.146774\n",
      "None         0.212903\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(get_pos_distribution(text, ['NOUN', None]).items(), headers=['POS', 'Distribution']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word       Count\n",
      "-------  -------\n",
      "чёрной         2\n",
      "этой           2\n",
      "красный        2\n",
      "этот           2\n",
      "таким          1\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(get_top_pos_words(text, 'ADJF', 5), headers=['Word', 'Count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

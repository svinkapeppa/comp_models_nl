{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Topic_Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3-dGfXbRim8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmp_THAuRinH",
        "colab_type": "text"
      },
      "source": [
        "Download the data using `fetch_20newsgroups()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AuyXfFRRinL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = fetch_20newsgroups(remove=(\"headers\", \"footer\", \"quotes\")).data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3Tpivl6RinR",
        "colab_type": "text"
      },
      "source": [
        "# Part 1. LDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjhtmsHrRinT",
        "colab_type": "text"
      },
      "source": [
        "## Task 1\n",
        "\n",
        "1. Create an object of class `CountVectorizer`\n",
        "2. Apply this class to the dataset. Store only top-1000 most common words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y31ejlZaRinU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I additionally remove stopwords, because otherwise the results would be noninterpreted\n",
        "cv = CountVectorizer(max_features=1000, stop_words=\"english\")\n",
        "data = cv.fit_transform(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaDD-bGSRina",
        "colab_type": "text"
      },
      "source": [
        "## Task 2\n",
        "\n",
        "Get the top-1000 most common words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG79INJHRinb",
        "colab_type": "code",
        "outputId": "9e2314a7-a9ad-4c5c-c553-a51885667d36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "feature_names = cv.get_feature_names()\n",
        "assert len(feature_names) == 1000\n",
        "\n",
        "for feature in feature_names[-10:]:\n",
        "    print(feature)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "writing\n",
            "written\n",
            "wrong\n",
            "x11\n",
            "xt\n",
            "year\n",
            "years\n",
            "yes\n",
            "york\n",
            "young\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykhgdw0eRing",
        "colab_type": "text"
      },
      "source": [
        "Train `LatentDirichletAllocation` with the following parameters:\n",
        "* `n_topics=20`\n",
        "* `max_iter=50`\n",
        "* `learning_method=\"batch\"`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfI8XlSLRini",
        "colab_type": "code",
        "outputId": "56fd850e-4141-4f56-ae23-5352f6588676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "lda = LatentDirichletAllocation(n_components=20, max_iter=50, learning_method=\"batch\")\n",
        "lda.fit(data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
              "                          evaluate_every=-1, learning_decay=0.7,\n",
              "                          learning_method='batch', learning_offset=10.0,\n",
              "                          max_doc_update_iter=100, max_iter=50,\n",
              "                          mean_change_tol=0.001, n_components=20, n_jobs=None,\n",
              "                          perp_tol=0.1, random_state=None,\n",
              "                          topic_word_prior=None, total_samples=1000000.0,\n",
              "                          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWCYhwdhRino",
        "colab_type": "text"
      },
      "source": [
        "Use the following function to print key words from each topic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lbpXIkeRinq",
        "colab_type": "code",
        "outputId": "4878b8db-4c5b-41e3-fd1b-6c5d6a49edd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "def print_top_words(model, feature_names, n_top_words=10):\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        print(f\"Topic {topic_idx}\")\n",
        "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
        "\n",
        "print_top_words(lda, feature_names)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 0\n",
            "said car just didn time know did day went like\n",
            "Topic 1\n",
            "edu available ftp image software version pub graphics faq mit\n",
            "Topic 2\n",
            "00 25 10 15 20 16 14 17 12 30\n",
            "Topic 3\n",
            "space nasa gov earth data launch high water engine cost\n",
            "Topic 4\n",
            "mr president people government think going stephanopoulos know american clinton\n",
            "Topic 5\n",
            "armenian turkish armenians people war jews israeli armenia world turks\n",
            "Topic 6\n",
            "university list research information internet cx 1993 mail group center\n",
            "Topic 7\n",
            "game team year games season play hockey league players win\n",
            "Topic 8\n",
            "thanks mail edu know new does price like email looking\n",
            "Topic 9\n",
            "ax max g9v b8f a86 145 pl 0d 1d9 34u\n",
            "Topic 10\n",
            "key encryption chip __ ___ keys clipper use security public\n",
            "Topic 11\n",
            "file output entry program section files jpeg line rules 02\n",
            "Topic 12\n",
            "drive card scsi disk mac bit hard video speed pc\n",
            "Topic 13\n",
            "windows window use using problem program screen display dos application\n",
            "Topic 14\n",
            "don just like think know people good ve make really\n",
            "Topic 15\n",
            "god jesus people believe israel does bible christian church life\n",
            "Topic 16\n",
            "gun law state control guns right rights states police government\n",
            "Topic 17\n",
            "com edu db cs ca dod uk internet bike ac\n",
            "Topic 18\n",
            "book question time point used evidence read article does example\n",
            "Topic 19\n",
            "000 10 new period vs san la 12 chicago toronto\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7R6ZKHWRinz",
        "colab_type": "text"
      },
      "source": [
        "# Part 2. Gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oC1S7v21Rin0",
        "colab_type": "text"
      },
      "source": [
        "Convert the corpus into Gensim-compatible format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsvymaWtRin0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = gensim.matutils.Sparse2Corpus(data, documents_columns=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5pmj3QkRin6",
        "colab_type": "text"
      },
      "source": [
        "## Task 3\n",
        "\n",
        "Create `id2word` dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrjCupqjRin6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2word = {}\n",
        "for feature in feature_names:\n",
        "    id2word[len(id2word)] = feature"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJj8iPW8Rin_",
        "colab_type": "text"
      },
      "source": [
        "## Task 4\n",
        "\n",
        "Train `LDA` from `gensim`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waGZIodwRioA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify `num_topics` to provide fair comparison between models\n",
        "lda = gensim.models.LdaModel(corpus=corpus, id2word=id2word, num_topics=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Orbqv8RioF",
        "colab_type": "text"
      },
      "source": [
        "Print most common words for each topic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2meZ1bmRioH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "5b19d44c-93e4-4183-d172-092acc17e718"
      },
      "source": [
        "lda.print_topics(lda.num_topics)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.042*\"00\" + 0.023*\"hockey\" + 0.019*\"50\" + 0.018*\"25\" + 0.017*\"games\" + 0.016*\"sale\" + 0.016*\"team\" + 0.016*\"edu\" + 0.015*\"new\" + 0.013*\"10\"'),\n",
              " (1,\n",
              "  '0.029*\"people\" + 0.023*\"don\" + 0.022*\"think\" + 0.015*\"just\" + 0.010*\"right\" + 0.010*\"israel\" + 0.010*\"know\" + 0.009*\"like\" + 0.009*\"good\" + 0.008*\"say\"'),\n",
              " (2,\n",
              "  '0.017*\"power\" + 0.015*\"space\" + 0.011*\"team\" + 0.010*\"nasa\" + 0.010*\"division\" + 0.009*\"station\" + 0.009*\"ground\" + 0.009*\"year\" + 0.009*\"think\" + 0.009*\"toronto\"'),\n",
              " (3,\n",
              "  '0.115*\"cx\" + 0.057*\"_o\" + 0.031*\"lk\" + 0.030*\"17\" + 0.027*\"w7\" + 0.026*\"chz\" + 0.025*\"86\" + 0.023*\"ah\" + 0.022*\"d9\" + 0.021*\"air\"'),\n",
              " (4,\n",
              "  '0.016*\"time\" + 0.016*\"know\" + 0.014*\"book\" + 0.013*\"does\" + 0.012*\"people\" + 0.010*\"books\" + 0.010*\"church\" + 0.009*\"just\" + 0.009*\"like\" + 0.009*\"world\"'),\n",
              " (5,\n",
              "  '0.058*\"edu\" + 0.035*\"com\" + 0.019*\"mail\" + 0.015*\"internet\" + 0.012*\"uk\" + 0.011*\"ac\" + 0.011*\"file\" + 0.010*\"cs\" + 0.010*\"send\" + 0.010*\"pgp\"'),\n",
              " (6,\n",
              "  '0.030*\"25\" + 0.029*\"10\" + 0.021*\"16\" + 0.019*\"14\" + 0.018*\"11\" + 0.017*\"12\" + 0.017*\"15\" + 0.016*\"13\" + 0.015*\"20\" + 0.015*\"18\"'),\n",
              " (7,\n",
              "  '0.725*\"ax\" + 0.054*\"max\" + 0.025*\"0d\" + 0.020*\"g9v\" + 0.014*\"a86\" + 0.013*\"145\" + 0.011*\"b8f\" + 0.009*\"3t\" + 0.009*\"_o\" + 0.008*\"pl\"'),\n",
              " (8,\n",
              "  '0.027*\"key\" + 0.019*\"people\" + 0.017*\"government\" + 0.013*\"said\" + 0.012*\"turkish\" + 0.011*\"armenian\" + 0.010*\"chip\" + 0.010*\"keys\" + 0.009*\"armenians\" + 0.008*\"public\"'),\n",
              " (9,\n",
              "  '0.063*\"god\" + 0.022*\"jesus\" + 0.015*\"believe\" + 0.015*\"bible\" + 0.014*\"people\" + 0.012*\"say\" + 0.010*\"christian\" + 0.010*\"just\" + 0.010*\"think\" + 0.010*\"don\"'),\n",
              " (10,\n",
              "  '0.020*\"file\" + 0.020*\"use\" + 0.017*\"code\" + 0.016*\"entry\" + 0.016*\"program\" + 0.013*\"section\" + 0.012*\"com\" + 0.011*\"sun\" + 0.011*\"application\" + 0.010*\"source\"'),\n",
              " (11,\n",
              "  '0.059*\"__\" + 0.045*\"___\" + 0.035*\"gm\" + 0.028*\"technology\" + 0.018*\"new\" + 0.016*\"administration\" + 0.014*\"national\" + 0.014*\"access\" + 0.013*\"president\" + 0.013*\"1993\"'),\n",
              " (12,\n",
              "  '0.029*\"like\" + 0.021*\"don\" + 0.020*\"just\" + 0.017*\"know\" + 0.017*\"car\" + 0.016*\"time\" + 0.012*\"ve\" + 0.011*\"new\" + 0.011*\"com\" + 0.010*\"think\"'),\n",
              " (13,\n",
              "  '0.017*\"year\" + 0.016*\"bike\" + 0.014*\"space\" + 0.014*\"dod\" + 0.012*\"good\" + 0.012*\"just\" + 0.011*\"10\" + 0.010*\"like\" + 0.009*\"edu\" + 0.009*\"earth\"'),\n",
              " (14,\n",
              "  '0.021*\"like\" + 0.020*\"university\" + 0.020*\"don\" + 0.020*\"edu\" + 0.017*\"ve\" + 0.012*\"000\" + 0.012*\"know\" + 0.010*\"work\" + 0.010*\"better\" + 0.009*\"heard\"'),\n",
              " (15,\n",
              "  '0.021*\"edu\" + 0.018*\"available\" + 0.016*\"image\" + 0.016*\"software\" + 0.016*\"ftp\" + 0.011*\"mail\" + 0.011*\"space\" + 0.010*\"data\" + 0.010*\"pub\" + 0.010*\"information\"'),\n",
              " (16,\n",
              "  '0.020*\"monitor\" + 0.020*\"apple\" + 0.016*\"just\" + 0.014*\"know\" + 0.013*\"chip\" + 0.012*\"drive\" + 0.012*\"chips\" + 0.011*\"use\" + 0.011*\"don\" + 0.011*\"does\"'),\n",
              " (17,\n",
              "  '0.023*\"windows\" + 0.022*\"drive\" + 0.016*\"use\" + 0.013*\"scsi\" + 0.013*\"disk\" + 0.012*\"thanks\" + 0.012*\"card\" + 0.011*\"problem\" + 0.011*\"dos\" + 0.011*\"bit\"'),\n",
              " (18,\n",
              "  '0.022*\"law\" + 0.019*\"use\" + 0.016*\"gun\" + 0.013*\"mr\" + 0.009*\"right\" + 0.009*\"state\" + 0.008*\"does\" + 0.008*\"control\" + 0.008*\"laws\" + 0.008*\"don\"'),\n",
              " (19,\n",
              "  '0.019*\"game\" + 0.015*\"time\" + 0.011*\"keyboard\" + 0.011*\"team\" + 0.011*\"good\" + 0.010*\"win\" + 0.010*\"use\" + 0.008*\"does\" + 0.008*\"best\" + 0.008*\"way\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HDXrpDuRioL",
        "colab_type": "text"
      },
      "source": [
        "## Task 5\n",
        "\n",
        "Train `LSI` from `gensim`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21TZQRF0RioL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify `num_topics` to provide fair comparison between models\n",
        "lsi = gensim.models.LsiModel(corpus=corpus, id2word=id2word, num_topics=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IkPJUFwRioR",
        "colab_type": "text"
      },
      "source": [
        "Print most common words for each topic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npBY-PsyRioR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "e1316f2d-d6ae-410d-b5cb-27aac6ad597f"
      },
      "source": [
        "lsi.print_topics(lsi.num_topics)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.997*\"ax\" + 0.072*\"max\" + 0.016*\"g9v\" + 0.012*\"b8f\" + 0.010*\"a86\" + 0.009*\"pl\" + 0.007*\"1d9\" + 0.006*\"1t\" + 0.006*\"145\" + 0.006*\"bhj\"'),\n",
              " (1,\n",
              "  '0.387*\"145\" + 0.378*\"a86\" + 0.374*\"b8f\" + 0.359*\"g9v\" + 0.324*\"0d\" + 0.226*\"1d9\" + 0.211*\"0t\" + 0.187*\"2di\" + 0.172*\"_o\" + 0.171*\"34u\"'),\n",
              " (2,\n",
              "  '-0.309*\"file\" + -0.248*\"edu\" + -0.171*\"use\" + -0.144*\"available\" + -0.129*\"com\" + -0.122*\"program\" + -0.121*\"information\" + -0.117*\"people\" + -0.117*\"pub\" + -0.114*\"ftp\"'),\n",
              " (3,\n",
              "  '0.972*\"db\" + 0.149*\"cs\" + 0.089*\"al\" + 0.082*\"cx\" + 0.064*\"bits\" + -0.041*\"file\" + -0.021*\"edu\" + 0.021*\"gas\" + 0.020*\"higher\" + 0.020*\"ah\"'),\n",
              " (4,\n",
              "  '-0.675*\"g9v\" + 0.507*\"0d\" + 0.331*\"_o\" + -0.182*\"b8f\" + 0.129*\"145\" + 0.128*\"6um\" + -0.113*\"1d9\" + 0.110*\"6ei\" + 0.096*\"3t\" + 0.088*\"75u\"'),\n",
              " (5,\n",
              "  '-0.244*\"10\" + -0.230*\"14\" + -0.225*\"16\" + -0.189*\"12\" + -0.186*\"25\" + -0.180*\"15\" + -0.178*\"20\" + -0.175*\"13\" + -0.174*\"11\" + -0.170*\"00\"'),\n",
              " (6,\n",
              "  '0.298*\"file\" + -0.233*\"stephanopoulos\" + -0.233*\"mr\" + -0.210*\"know\" + -0.201*\"said\" + -0.197*\"people\" + -0.186*\"don\" + 0.161*\"edu\" + -0.157*\"think\" + -0.156*\"president\"'),\n",
              " (7,\n",
              "  '0.589*\"g9v\" + 0.448*\"0d\" + -0.285*\"b8f\" + 0.284*\"_o\" + -0.198*\"pl\" + -0.182*\"1d9\" + -0.177*\"0t\" + -0.161*\"145\" + -0.146*\"a86\" + -0.136*\"wm\"'),\n",
              " (8,\n",
              "  '-0.642*\"file\" + 0.310*\"edu\" + -0.252*\"output\" + -0.179*\"entry\" + -0.159*\"gun\" + 0.137*\"available\" + -0.129*\"mr\" + 0.127*\"com\" + 0.103*\"pub\" + -0.092*\"congress\"'),\n",
              " (9,\n",
              "  '0.602*\"jpeg\" + 0.321*\"image\" + 0.235*\"gif\" + -0.186*\"edu\" + 0.185*\"color\" + 0.156*\"images\" + 0.147*\"bit\" + -0.144*\"com\" + 0.131*\"format\" + 0.120*\"quality\"'),\n",
              " (10,\n",
              "  '-0.498*\"mr\" + -0.484*\"stephanopoulos\" + -0.241*\"president\" + 0.235*\"people\" + -0.157*\"edu\" + 0.113*\"god\" + 0.105*\"didn\" + 0.100*\"entry\" + 0.099*\"like\" + -0.095*\"package\"'),\n",
              " (11,\n",
              "  '0.612*\"cx\" + 0.438*\"w7\" + 0.284*\"chz\" + 0.268*\"lk\" + 0.212*\"17\" + 0.148*\"d9\" + -0.125*\"a86\" + -0.122*\"b8f\" + 0.118*\"27\" + 0.116*\"34u\"'),\n",
              " (12,\n",
              "  '-0.323*\"entry\" + -0.304*\"output\" + -0.229*\"program\" + 0.214*\"file\" + 0.202*\"jpeg\" + 0.184*\"gun\" + -0.118*\"stephanopoulos\" + -0.118*\"rules\" + -0.116*\"build\" + 0.113*\"privacy\"'),\n",
              " (13,\n",
              "  '0.362*\"edu\" + -0.222*\"privacy\" + -0.207*\"use\" + -0.205*\"internet\" + 0.161*\"com\" + 0.160*\"hockey\" + 0.159*\"output\" + -0.157*\"anonymous\" + 0.123*\"said\" + -0.122*\"disk\"'),\n",
              " (14,\n",
              "  '0.215*\"00\" + -0.202*\"file\" + 0.196*\"entry\" + 0.189*\"privacy\" + -0.184*\"scsi\" + 0.180*\"internet\" + -0.176*\"disk\" + -0.174*\"drive\" + -0.166*\"gun\" + 0.154*\"anonymous\"'),\n",
              " (15,\n",
              "  '-0.292*\"hockey\" + -0.225*\"new\" + -0.208*\"league\" + -0.187*\"nhl\" + -0.185*\"team\" + -0.171*\"season\" + -0.147*\"year\" + 0.146*\"file\" + 0.138*\"widget\" + -0.131*\"space\"'),\n",
              " (16,\n",
              "  '-0.811*\"00\" + -0.219*\"dos\" + 0.152*\"55\" + -0.141*\"50\" + -0.134*\"appears\" + -0.109*\"art\" + -0.101*\"40\" + 0.094*\"14\" + 0.085*\"entry\" + 0.081*\"12\"'),\n",
              " (17,\n",
              "  '-0.211*\"edu\" + 0.204*\"widget\" + 0.181*\"window\" + -0.172*\"output\" + 0.159*\"subject\" + 0.156*\"use\" + -0.152*\"internet\" + -0.145*\"anonymous\" + -0.142*\"privacy\" + 0.135*\"wire\"'),\n",
              " (18,\n",
              "  '-0.382*\"34u\" + 0.351*\"145\" + -0.316*\"1d9\" + -0.268*\"pl\" + -0.267*\"sl\" + 0.261*\"a86\" + -0.246*\"3t\" + 0.221*\"cx\" + -0.195*\"2tm\" + 0.186*\"b8f\"'),\n",
              " (19,\n",
              "  '0.449*\"space\" + 0.224*\"data\" + -0.224*\"god\" + 0.222*\"launch\" + 0.158*\"nasa\" + 0.146*\"satellite\" + 0.134*\"image\" + -0.125*\"use\" + -0.122*\"jpeg\" + -0.116*\"jesus\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CUc_A3MRioV",
        "colab_type": "text"
      },
      "source": [
        "Which model highlighted the topics most successfully?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DIqobahZhmz",
        "colab_type": "text"
      },
      "source": [
        "Мне кажется, лучше всего получилось выделить темы у `LDA` из `sklearn`. Если посмотреть на самые популярные слова в темах, то можно будет даже как-то их интерпретировать: спорт, политический конфликт США и Израиля, космос, цифры.\n",
        "\n",
        "В `LDA` из `gensim` в целом тоже можно найти какие-то темы, но все как-то спутано и добавляются лишние слова.\n",
        "\n",
        "В `LSI` все вообще плохо -- просто набор каких-то несвязанных слов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3QTpkn0RioW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}